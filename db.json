{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/img/icon_wechat.png","path":"img/icon_wechat.png","modified":0,"renderable":0},{"_id":"source/img/article/tag.png","path":"img/article/tag.png","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/css/archive.styl","path":"css/archive.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/beantech.css","path":"css/beantech.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/beantech.min.css","path":"css/beantech.min.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/donate.css","path":"css/donate.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/rocket.styl","path":"css/rocket.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/signature.styl","path":"css/signature.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/toc.styl","path":"css/toc.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/widget.styl","path":"css/widget.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/hux-blog.js","path":"js/hux-blog.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/toc.js","path":"js/toc.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"source/img/header_img/about.jpg","path":"img/header_img/about.jpg","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"source/img/header_img/archive.jpg","path":"img/header_img/archive.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/archives-widget.jpg","path":"img/header_img/archives-widget.jpg","modified":0,"renderable":0},{"_id":"source/img/signature/BeanTechSign-white.png","path":"img/signature/BeanTechSign-white.png","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/css/bootstrap.css","path":"css/bootstrap.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/images/ironman.png","path":"css/images/ironman.png","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/images/rocket.png","path":"css/images/rocket.png","modified":0,"renderable":1},{"_id":"source/img/signature/BeanTechSign-black.png","path":"img/signature/BeanTechSign-black.png","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/js/jquery.js","path":"js/jquery.js","modified":0,"renderable":1},{"_id":"source/img/article_header/article_bg.jpg","path":"img/article_header/article_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/avatar/wenjing-liu.jpg","path":"img/avatar/wenjing-liu.jpg","modified":0,"renderable":0},{"_id":"source/img/article/huweihuang_blog.png","path":"img/article/huweihuang_blog.png","modified":0,"renderable":0},{"_id":"source/img/blog.jpg","path":"img/blog.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/home.jpg","path":"img/header_img/home.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/tag.png","path":"img/header_img/tag.png","modified":0,"renderable":0},{"_id":"source/img/article_header/article_header.png","path":"img/article_header/article_header.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-o.png","path":"img/header_img/home-bg-o.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home2.png","path":"img/header_img/home2.png","modified":0,"renderable":0},{"_id":"source/img/header_img/404.png","path":"img/header_img/404.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/404.md","hash":"8aa56af7bcd7cd23667cbf3eb5b5c9fa4533eb60","modified":1553613482000},{"_id":"source/CNAME","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1554274287047},{"_id":"themes/huweihuang/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1553613482000},{"_id":"themes/huweihuang/_config.yml","hash":"e800e32847df32dacddb5202823a004557023bcd","modified":1553613482000},{"_id":"source/_posts/2019-07-29-特征工程.md","hash":"806eefaf7c2fe3d12f88b27e94685c5bb5a179d0","modified":1564478923546},{"_id":"source/_posts/2019-07-30-机器学习优化方法.md","hash":"98cfdb18f61158cc4a12c85ef5c59913d563a5b2","modified":1564654118473},{"_id":"source/_posts/2019-07-31-2019-下半年学习计划.md","hash":"602491051b3ce233d6eb0cd4b49f1495b6cee94c","modified":1564558727028},{"_id":"source/_posts/JavaScript-2018-Frame.md","hash":"11dec45f11de14beee4e6fa2f5d88a10b8ae6376","modified":1554273995614},{"_id":"source/about/index.md","hash":"593416287b0516ce3652c96ddbd0fa80b6453529","modified":1564367743427},{"_id":"source/archive/index.md","hash":"8a773a78ba3dad1ee3f7c7b916788046c89860fb","modified":1564367779190},{"_id":"source/img/icon_wechat.png","hash":"4188058026609de06c6cac88b349a2da831a1783","modified":1553613482000},{"_id":"source/tags/index.md","hash":"f6ad1039c242795de5cd7d81781148f8c5298c28","modified":1554273478614},{"_id":"themes/huweihuang/languages_to_be_added/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1553613482000},{"_id":"themes/huweihuang/languages_to_be_added/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1553613482000},{"_id":"themes/huweihuang/layout/404.ejs","hash":"40de38bd399f6f4aef0d6c63c7b13b02d74f1c56","modified":1553613482000},{"_id":"themes/huweihuang/layout/about.ejs","hash":"edcf8fa3bf7093c974d418ffef42ac89c19af128","modified":1553613482000},{"_id":"themes/huweihuang/layout/archive.ejs","hash":"72a150c8dff0031a9107d12eaa7c2e6c6ce950d2","modified":1553613482000},{"_id":"themes/huweihuang/layout/index.ejs","hash":"dc8a6eaa00d1e7c33a40979afe0953ed5d7b512e","modified":1553613482000},{"_id":"themes/huweihuang/layout/keynote.ejs","hash":"f5689862281e34dbe8402b0e72f632902e53e88b","modified":1553613482000},{"_id":"themes/huweihuang/layout/layout.ejs","hash":"a5af5b99ac3456ab5da1a319455904b979b91601","modified":1553613482000},{"_id":"themes/huweihuang/layout/page.ejs","hash":"5e588f200a7b7cd3ae40402b0dd3b779aac6787f","modified":1553613482000},{"_id":"themes/huweihuang/layout/post.ejs","hash":"4832891997c9d962c8b7b7bce6a778a25df41718","modified":1564466146414},{"_id":"themes/huweihuang/layout/tags.ejs","hash":"2c72eb2e89130658aa068d80d27b561b509c5dcd","modified":1553613482000},{"_id":"source/img/article/tag.png","hash":"c8632d64d9471009098b84f70273e63037a4e7b8","modified":1553613482000},{"_id":"themes/huweihuang/layout/_partial/footer.ejs","hash":"66ec1893e4541a191af958a01b618674e4f70313","modified":1554273877901},{"_id":"themes/huweihuang/layout/_partial/head.ejs","hash":"9d223bf2f445addd28746117119b923a6c8f8588","modified":1564381069973},{"_id":"themes/huweihuang/layout/_partial/header.ejs","hash":"3bd09df76e0622d76d186b020393fcab361e6c97","modified":1553613482000},{"_id":"themes/huweihuang/layout/_partial/nav.ejs","hash":"4c905166c960852e9b9a3c9d5c680091e37b481f","modified":1553613482000},{"_id":"themes/huweihuang/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1553613482000},{"_id":"themes/huweihuang/layout/_partial/sidebar.ejs","hash":"2e4e528a555917b2a267da4db2440bcc4a7a65ab","modified":1553613482000},{"_id":"themes/huweihuang/layout/_partial/toc.ejs","hash":"40e11b303df113c64a5ca35b79dd53c824010c09","modified":1553613482000},{"_id":"themes/huweihuang/layout/_widget/archive.ejs","hash":"7594929d472806ca4c64d9906d9903a96de111a0","modified":1553613482000},{"_id":"themes/huweihuang/layout/_widget/category.ejs","hash":"1cf485def07dc06e870dc9613767c6c614bcf428","modified":1553613482000},{"_id":"themes/huweihuang/layout/_widget/featured-tags.ejs","hash":"0c9ce1942f1943dc8891a9302a922ef1ffe300c5","modified":1553613482000},{"_id":"themes/huweihuang/layout/_widget/friends-blog.ejs","hash":"734d3775017aedac185028924baf890a71a74548","modified":1553613482000},{"_id":"themes/huweihuang/layout/_widget/recent-posts.ejs","hash":"e08ab8ba60e31638006acf27f066b989a0a3c433","modified":1553613482000},{"_id":"themes/huweihuang/layout/_widget/short-about.ejs","hash":"315de02246f07c747c32495e107ad7b19cb3ff54","modified":1553613482000},{"_id":"themes/huweihuang/source/css/archive.styl","hash":"715bcbd085eb95ec26c9805c11c374919cde971c","modified":1553613482000},{"_id":"themes/huweihuang/source/css/beantech.css","hash":"4c361354fd8e9851923fb21a620bc079380ebcd8","modified":1553613482000},{"_id":"themes/huweihuang/source/css/beantech.min.css","hash":"05a06230b1a9eca0b30cece54a397008cb77dc50","modified":1553613482000},{"_id":"themes/huweihuang/source/css/donate.css","hash":"f65ac8363d8d215adb896158e7b45165db259a47","modified":1553613482000},{"_id":"themes/huweihuang/source/css/highlight.styl","hash":"e842080e6d580f0f70a7df71fbde3c4e49463c19","modified":1553613482000},{"_id":"themes/huweihuang/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1553613482000},{"_id":"themes/huweihuang/source/css/rocket.styl","hash":"e15c51c8566ecd943112e57592888dd318b6fa6a","modified":1553613482000},{"_id":"themes/huweihuang/source/css/signature.styl","hash":"88159b31c59d59c01a0b534af57242662a2a3969","modified":1553613482000},{"_id":"themes/huweihuang/source/css/toc.styl","hash":"631e97f634d30f53314e2fec8bdde267c1c49f4c","modified":1553613482000},{"_id":"themes/huweihuang/source/css/widget.styl","hash":"7a9f735f5ef323dc2950fbd9d76daa16c9a0f1a9","modified":1553613482000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1553613482000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1553613482000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1553613482000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1553613482000},{"_id":"themes/huweihuang/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1553613482000},{"_id":"themes/huweihuang/source/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1553613482000},{"_id":"themes/huweihuang/source/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1553613482000},{"_id":"themes/huweihuang/source/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1553613482000},{"_id":"themes/huweihuang/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1553613482000},{"_id":"themes/huweihuang/source/js/toc.js","hash":"41e52551731854224c249d53010c1bae5aa92ffa","modified":1553613482000},{"_id":"themes/huweihuang/source/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1553613482000},{"_id":"source/img/header_img/about.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1553613482000},{"_id":"themes/huweihuang/source/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1553613482000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1553613482000},{"_id":"themes/huweihuang/source/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1553613482000},{"_id":"themes/huweihuang/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1553613482000},{"_id":"source/img/header_img/archive.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1553613482000},{"_id":"source/img/header_img/archives-widget.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1553613482000},{"_id":"source/img/signature/BeanTechSign-white.png","hash":"34289ed41cf9ddac2d56be46fbb1515b7d5913cd","modified":1553613482000},{"_id":"themes/huweihuang/source/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1553613482000},{"_id":"themes/huweihuang/source/css/images/ironman.png","hash":"2f0db0ab15d466c4065d9f6102fdf829726d9e3f","modified":1553613482000},{"_id":"themes/huweihuang/source/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1553613482000},{"_id":"source/img/signature/BeanTechSign-black.png","hash":"94b7102e819fd6ee082d3fb0166f4de7458c22ff","modified":1553613482000},{"_id":"themes/huweihuang/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1553613482000},{"_id":"source/img/article_header/article_bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1553613482000},{"_id":"source/img/avatar/wenjing-liu.jpg","hash":"adb893c8013f3befbd8cdc4c71235862a2f39253","modified":1554273086961},{"_id":"source/img/article/huweihuang_blog.png","hash":"392cf8b33be6c752dd908e027fa3346a6ecd58ab","modified":1553613482000},{"_id":"source/img/blog.jpg","hash":"a76af0b98dbe92ca2d21babcef13f094e409554b","modified":1553613482000},{"_id":"source/img/header_img/home.jpg","hash":"8f1c440427a4aa86b623503a926c027e2e10cd66","modified":1553613482000},{"_id":"source/img/header_img/tag.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1553613482000},{"_id":"source/img/article_header/article_header.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1553613482000},{"_id":"source/img/header_img/home-bg-o.png","hash":"134ece4cb4c49c7ca1403a5afe7f46d0e2f9ecbb","modified":1553613482000},{"_id":"source/img/header_img/home2.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1553613482000},{"_id":"source/img/header_img/404.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1553613482000},{"_id":"source/_posts/框架以及工具总结.md","hash":"430d9a557b9c9f262250b369e23adf9dd688d685","modified":1564730623207}],"Category":[],"Data":[],"Page":[{"layout":"404","description":"你来到了没有知识的荒原","header-img":"/img/header_img/404.png","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"你来到了没有知识的荒原\"\nheader-img: \"/img/header_img/404.png\"\n---\n","date":"2019-04-03T06:11:14.503Z","updated":"2019-03-26T15:18:02.000Z","path":"404.html","title":"","comments":1,"_id":"cjysio1pf0000chovxfjfc9l7","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"about","title":"About","date":"2019-07-28T16:00:00.000Z","description":"","header-img":"/img/header_img/about.jpg","aplayer":true,"fixed":false,"_content":"\n###\n\n>\n\n### 关于我\n\n> 一个曾经搞前端的\n> 一个曾经搞JS web全栈的\n> 一个现在专注于数据科学的工程师\n\n### 兴趣方向\n\n> 前端开发\n> JS 全栈\n> 机器学习\n> 深度学习\n> 数据分析\n\n### 参与社区\n >\n > Github:https://github.com/wenjing-liu\n\n\n### 联系我\n\n>Email: wenjing.liu09@foxmail.com\n\n","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"About\"\ndate: 2019-07-29\ndescription: \"\"\nheader-img: \"/img/header_img/about.jpg\"\naplayer: true\nfixed: false\n---\n\n###\n\n>\n\n### 关于我\n\n> 一个曾经搞前端的\n> 一个曾经搞JS web全栈的\n> 一个现在专注于数据科学的工程师\n\n### 兴趣方向\n\n> 前端开发\n> JS 全栈\n> 机器学习\n> 深度学习\n> 数据分析\n\n### 参与社区\n >\n > Github:https://github.com/wenjing-liu\n\n\n### 联系我\n\n>Email: wenjing.liu09@foxmail.com\n\n","updated":"2019-07-29T02:35:43.427Z","path":"about/index.html","comments":1,"_id":"cjysio1q40002chovj1eou61p","content":"<h3 id=\"\"><a class=\"markdownIt-Anchor\" href=\"#\"></a> </h3>\n<blockquote></blockquote>\n<h3 id=\"关于我\"><a class=\"markdownIt-Anchor\" href=\"#关于我\"></a> 关于我</h3>\n<blockquote>\n<p>一个曾经搞前端的<br>\n一个曾经搞JS web全栈的<br>\n一个现在专注于数据科学的工程师</p>\n</blockquote>\n<h3 id=\"兴趣方向\"><a class=\"markdownIt-Anchor\" href=\"#兴趣方向\"></a> 兴趣方向</h3>\n<blockquote>\n<p>前端开发<br>\nJS 全栈<br>\n机器学习<br>\n深度学习<br>\n数据分析</p>\n</blockquote>\n<h3 id=\"参与社区\"><a class=\"markdownIt-Anchor\" href=\"#参与社区\"></a> 参与社区</h3>\n<blockquote>\n<p>Github:<a href=\"https://github.com/wenjing-liu\" target=\"_blank\" rel=\"noopener\">https://github.com/wenjing-liu</a></p>\n</blockquote>\n<h3 id=\"联系我\"><a class=\"markdownIt-Anchor\" href=\"#联系我\"></a> 联系我</h3>\n<blockquote>\n<p>Email: <a href=\"mailto:wenjing.liu09@foxmail.com\" target=\"_blank\" rel=\"noopener\">wenjing.liu09@foxmail.com</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"\"><a class=\"markdownIt-Anchor\" href=\"#\"></a> </h3>\n<blockquote></blockquote>\n<h3 id=\"关于我\"><a class=\"markdownIt-Anchor\" href=\"#关于我\"></a> 关于我</h3>\n<blockquote>\n<p>一个曾经搞前端的<br>\n一个曾经搞JS web全栈的<br>\n一个现在专注于数据科学的工程师</p>\n</blockquote>\n<h3 id=\"兴趣方向\"><a class=\"markdownIt-Anchor\" href=\"#兴趣方向\"></a> 兴趣方向</h3>\n<blockquote>\n<p>前端开发<br>\nJS 全栈<br>\n机器学习<br>\n深度学习<br>\n数据分析</p>\n</blockquote>\n<h3 id=\"参与社区\"><a class=\"markdownIt-Anchor\" href=\"#参与社区\"></a> 参与社区</h3>\n<blockquote>\n<p>Github:<a href=\"https://github.com/wenjing-liu\" target=\"_blank\" rel=\"noopener\">https://github.com/wenjing-liu</a></p>\n</blockquote>\n<h3 id=\"联系我\"><a class=\"markdownIt-Anchor\" href=\"#联系我\"></a> 联系我</h3>\n<blockquote>\n<p>Email: <a href=\"mailto:wenjing.liu09@foxmail.com\" target=\"_blank\" rel=\"noopener\">wenjing.liu09@foxmail.com</a></p>\n</blockquote>\n"},{"layout":"archive","title":"Archives","header-img":"/img/header_img/archive.jpg","comments":0,"date":"2019-07-20T12:49:56.000Z","description":"Hey, this is archives","_content":"","source":"archive/index.md","raw":"---\nlayout: \"archive\"\ntitle: \"Archives\"\nheader-img: \"/img/header_img/archive.jpg\"\ncomments: false\ndate: 2019-07-20 20:49:56\ndescription: \"Hey, this is archives\"\n---\n","updated":"2019-07-29T02:36:19.190Z","path":"archive/index.html","_id":"cjysio1q60004chovu25lae7q","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"tags","title":"Tags","description":"Hey, this is Tags.","header-img":"/img/header_img/tag.png","_content":"","source":"tags/index.md","raw":"---\nlayout: \"tags\"\ntitle: \"Tags\"\ndescription: \"Hey, this is Tags.\"\nheader-img: \"/img/header_img/tag.png\"\n---\n","date":"2019-04-03T06:37:58.614Z","updated":"2019-04-03T06:37:58.614Z","path":"tags/index.html","comments":1,"_id":"cjysio1qa0007chovpq6a55kj","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"特征工程","catalog":true,"toc_nav_num":true,"date":"2019-07-29T10:30:24.000Z","subtitle":null,"header-img":"/img/article_header/article_header.png","catagories":["机器学习"],"_content":"\n> 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已\n> 实践中学习的手艺\n> More data beats clever algorithms, but better data beats more data\n\n### 特征工程包含以下几个方面：\n#### 特征使用方案\n* 要实现我们的目标需要哪些数据？\n  - 基于业务理解，尽可能找出对因变量有影响的所有自变量\n* 可用性评估\n  - 获取难度\n  - 覆盖率\n  - 准确率\n\n#### 特征获取方案\n* 如何获取这些特征？\n* 如何存储？\n\n#### 特征处理\n* 特征特征清洗\n  - 清洗异样样本\n  - 采样\n    + 数据不均衡\n    + 样本权重\n* 预处理\n  - 单个特征\n    + 归一化\n    + 离散化\n    + Dummy Coding\n    + 缺失值\n    + 数据变换\n      - log\n      - 指数\n      - Box-Cox\n  - 多个特征\n    + Filter\n      - 思路：自变量和目标变量之间的关联\n      - 相关系数\n      - 卡方检验\n      - 信息增益、 互信息\n    + Wrapper\n      - 思路: 通过目标函数（AUC/MSE）来决定是否加入一个变量\n      - 迭代：产生特征子集，评价\n        + 完全搜索\n        + 启发式搜索\n        + 随机搜索\n          - GA\n          - SA\n    + Embedded\n      - 思路：学习期自身自动选择特征\n      - 正则化\n        + L1 -- Lasso\n        + L2 -- Ridge\n      - 决策树 -- 熵、信息增益\n      - 深度学习\n  - 衍生变量 -- 对原始数据加工，生成有商业意义的变量\n\n#### 特征监控\n* 特征有效性分析\n* 特征监控\n\n### 最基本的特征工程方法\n#### 类别特征\n  * 特点\n    - 几乎总是需要一些处理\n    - 高基数可以创建非常稀疏的数据\n    - 很难插补缺失数据\n  * 方法\n    - 独热编码（One-Hot Encoding）\n      + 概念\n        - 在长度为K的数组上做 one-of-k 编码\n        - 基本方法： 与大多数线性算法一起使用\n        - 删除第一列可以避免多重共线性\n        - 稀疏格式对内存友好\n        - 当前大多数实现都没有处理缺失，看不见的数据\n      + 例子\n        - ['BR']\n          | 国家  =>|国家=NL  | 国家=BR  | 国家=US  |\n          |---|---|---|---|---|---|\n          |  NL | |||\n          |  BR | [   0|   1|   0]|\n          |  US |   |||\n        - 编码集：[0, 1, 0]\n        - 编码稀疏： 2:1\n    - 散列编码（Hash encoding)\n      + 概念\n        - 独热编码是否具有固定长度的数组？\n        - 避免极其稀疏的数据\n        - 可能会引入碰撞\n        - 可以重复的使用不同的哈希函数和包获得小的精度\n        - 碰撞通常会降低结果，但可能会改善结果\n        - 优雅地处理新变量（例如：新用户代理）\n      + 例子\n        - ['BR']\n        - hash('BR') =>\n          | 国家  | hash1  | hash2 | hash3  | hash4| hash5|\n          |---|---|---|---|---|---|\n          |  NL |   |   |   |   ||\n          |  BR |[   0|   1|   0|   0| 0]|\n          |  US |   |   |   |   ||\n        - 编码集：[0, 1, 0, 0, 0]\n        - 编码稀疏： 2:1\n\n    - 标签编码（Label encoding）\n      + 概念\n        - 为每个类别变量提供唯一的数字ID\n        - 对于非线性基于树的算法很有用\n        - 不增加维度\n        - 随机化类别变量到数值变量的映射并重新训练， 平均以获得精度较小的凸凹\n      + 例子\n        - ['Queenstown']\n          | 城市  =>| city  |\n          |---|---|\n          |  Cherbourg |  1 |\n          |  Queenstown |  2 |\n          |  Southhampton |  3 |\n        - 编码： [2]\n    - 计数编码（Count encoding）\n      + 概念\n        - 将类别变量替换为他们在训练数据中的计数\n        - 适用于线性和非线性算法\n        - 可以对异常值敏感\n        - 可以加入对数转换（log transform）, 与计数一起工作的很好\n        - 用‘1’替换看不见的数据\n        - 可能会发生冲突：相同的编码，不同的变量\n      + 例子\n        - ['A6GHBD78']\n          | teacher_id  |   teacher_id|\n          |---|---|---|\n          |  DEADB33F |   4|\n          |  A6GHBD78|   3|\n          |  DEADB33F |   4|\n          |  FCKGWRHQ |   1|\n          |  DEADB33F |   4|\n          |  A6GHBD78|   3|\n          |  A6GHBD78|   3|\n          |  DEADB33F |   4|\n        - 编码： [3]\n    - 标签计数编码（LabelCount encoding）\n      + 概念\n        - 在训练数据中，对类别变量进行排名\n        - 适用于线性和非线性算法\n        - 对异常值不敏感\n        - 不会对不同的变量赋予相同的编码\n        - 两全其美\n      + 例子\n        - ['nl']\n          | tld  |   tld|\n          |---|---|---|\n          |  nl |   3|\n          |  nl|   3|\n          |  nl |   3|\n          |  nl |   3|\n          |  de |   2|\n          |  de|   2|\n          |  fr|   1|\n          |  fr |   1|\n        - 编码： [3]\n    - Target encoding\n      + 概念\n        - 根据目标比率对类别变量进行编码（二进制分类或回归）\n        - 小心避免过度拟合（overfit）\n        - 堆叠的形式：单变量模型，其输出平均目标\n        - 以交叉验证方式进行\n        - 添加平滑以避免将变量编码设置为0\n        - 添加随机噪音以对抗过拟合\n        - 什么时候用：线性和非线性的最佳编码\n      + 例子\n        | role  |  y |  role |\n        |---|---|---|---|---|\n        |  manager |  1 |  0.5 |\n        |  engineer |  1 |   0.66|\n        |  scientist |  1 |   1.|\n        | manager| 0|0.5|\n        | engineer|0|0.66|\n        | engineer|1|0.66|\n\n    - 类别嵌入（Category Embedding）\n      + 概念\n        - 使用神经网络从类别变量创建密集嵌入\n        - 将函数逼近问题中的类别变量映射到欧几里德空间\n        - 更快的模型训练\n        - 减少内存开销\n        - 可以提供比1-hot 编码更好的精准度\n      + 例子\n        | role  |  role 3-D embedding |\n        |---|---|\n        |  manager |  [0.05, 0.10, 0.96] |\n        |  engineer | [0.72, 0.66, 0.17]|\n        |  scientist |  [0.75, 0.62, 0.15]|\n        | manager| [0.05, 0.10, 0.96]|\n        | engineer|[0.72, 0.66, 0.17]|\n        | engineer|[0.72, 0.66, 0.17]|\n\n    - NaN编码（NaN encoding）\n      + 概念\n        - 为NaN值提供显式编码而不是忽略\n        - NaN值可以保存信息\n        - 小心避免过度拟合\n        - 仅在训练数据和测试数据中的Nan值是由相同的原因引起时才可以用，或者本地验证证明它持有信息\n      + 例子\n        - ['NaN']\n          | UA | UA=mobile| UA=tablet| UA=NaN|\n          |---|---|---|---|\n          |mobile| |||\n          |tablet||||\n          |mobile||||\n          |NaN|0|0|1|\n          |mobile||||\n        - 编码： [0, 0, 1]\n\n    - 多项式编码（Polynomial encoding）\n      + 概念\n        - 类别变量之间的编码交互\n        - 没有交互的线性算法无法解决XOR问题\n        - 多项式内核可以解决XOR问题\n        - 爆炸式的特征空间： 使用FS，散列或者VW\n      + 例子\n        |A  |B  |y  | A=1*B=1| A=0*B=1| A=1*B=0 | A=0*B=0| y|\n        |---|---|---|---|---|---|---|---|\n        |1  |1  | 1 | 1|   0|  0|0|1 |\n        |0  |1  | 0 | 0|   1|  0|0|0 |\n        |1  |0  | 0 | 0|   0|  1|0|0 |\n        |0  |0  | 1 | 0|   0|  0|1|1 |\n    - 扩展编码（Expansion encoding）\n      + 概念\n        - 从单个变量创建多个类别变量\n        - 某些高基数功能（如用户代理）在其中包含更多信息：\n          + is_mobile?\n          + is_latest_version?\n          + Operation_system\n          + Browser_build\n          + etc...\n      + 例子\n        - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\n          ==>\n          |UA1|UA2|UA3|UA4|UA5|\n          |---|---|---|---|---|\n          |Chrome|53.0.2785.143|Desktop|Mac|10_10_4|\n    - 合并编码（Consolidation encoding）\n      + 概念\n        - 将不同的类别变量映射到同一个变量\n        - 拼写错误，略有不同的职位描述，全名 vs 缩写\n        - 真实数据很乱，自由文本尤其如此\n      + 例子\n        |company_desc   =>| desc1| company_desc2|\n        |---------------|------|--------------|\n        |Shell          | Shell|Gas station|\n        |shel           | Shell|Gas station|\n        |SHELL          | Shell|Gas station|\n        |Shell Gasonline| Shell|Gas station|\n        |BP             | BP| Gas station|\n        |British Petr. | BP | Gas station|\n        |B&P           | BP | Gas station|\n        |BP Gas Station| BP| Gas station|\n        |bp            | BP | Gas station|\n        |Procter&Gamble| P&G| Manufacturer|\n#### 数值特征\n* 特点\n  - 可以更容易地输入算法\n  - 可以构成浮点数，计数，数字\n  - 更容易估算缺失的数据\n* 方法\n  - 四舍五入（Rounding）\n    + 概念\n      - 四舍五入数值变量\n      - 有损压缩： 保留数据的最重要特征\n      - 有时太精确只是噪音\n      - 四舍五入的变量可以视为类别变量\n      - 可以在四舍五入之前做对数变换\n    + 例子\n      |age | age1|age2|\n      |---|---|---|\n      |23.6671| 23|2|\n      |23.8891|23|2|\n      |22.1261|22|2|\n      |19.5506|19|1|\n      |18.2114|18|1|\n  - 分档（Binning）\n    + 概念\n      - 将数值变量放入bin（档）中并使用bin-ID进行编码\n      - 分档可以务实设置，通过分位数，均匀的，或使用模型到最佳分档\n      - 可以使得训练集所见范围以外的变量正常工作\n    + 例子\n      |risk_score| rs[-inf, 33]| rs[33,66]|rs[66,inf]|\n      |---|---|---|---|\n      |15| 1|0|0|\n      |77|0|0|1|\n      |78|0|0|1|\n      |55|0|1|0|\n      |42|0|1|0|\n  - 缩放（Scaling）\n    + 概念\n      - 将数值变量扩展到特定范围\n      - Standard（Z）缩放\n      - MinMax 缩放\n      - Root 缩放\n      - Log 缩放\n  - 估算（Imputation）\n    + 概念\n      - 估算缺失的变量\n      - 硬编码可与估算相结合\n      - 平均：非常基本的\n      - 中位数：对异常值鲁棒性比较高\n      - 忽略： 只是推迟问题\n      - 使用模型：可以暴露算法的偏差\n    + 例子\n      |wage|hours|gender|y => | wage|hours|gender_y|\n      |---|---|---|---|---|---|---|\n      |1600|40|0|1|1600|40|0|\n      |2200|50|1|1|2200|50|1|\n      |1800|36|0|0|1800|36|0|\n      |2100|45|1|0|2100|45|?|\n      |2050|60|NaN|0|2050|60|?|\n      |1650|36|0|1|1650|36|?|\n  - 相互作用（Interactions）\n    + 概念\n      - 具体来说编码数值变量之间的相互作用\n      - 尝试：减法，加法，乘法，除法\n      - 使用：通过统 计测试选择特征，或训练模型特征重要性\n      - 忽略：人的直觉; 奇怪的相互作用可以带来显著的改进\n  - 线性算法的非线性编码（No-linear encoding for linear algo's）\n    + 概念\n      - 硬编码非线性以改进线性算法\n      - 多项式内核\n      - 叶编码（随机森林嵌入）\n      - 遗传算法\n      - 局部线性嵌入，光谱嵌入，t-SNE\n  - 行统计（Row statistics）\n    + 概念\n      - 创建一行数据的统计信息\n      - NaN的数量\n      - 0的数量\n      - 负数值的数量\n      - 平均值，最大值，最小值，偏度 等\n#### 时间特征 (Temporal variables)\n* 特点\n  - 时间变量，如日期，需要更好的本地验证方案（如回测）\n  - 容易在这里犯错误\n  - 很多机会进行重大改进\n* 方法\n  - 投射到一个圆\n    + 将单个要素（如day_of_week）转换为圆上的两个坐标\n    + 确保max和min之间的距离与min和min +1相同\n    + 用于day_of_week，day_of_month，hour_of_day等\n  - 趋势线（Trendlines）\n    + 不是编码总支出，而是编码上周花费，上个月花费，去年花费。\n    + 给算法的趋势：两个支出相同的客户可能会有截然不同的行为 - 一个客户可能开始花费更多，而另一个客户开始减少支出。\n  - 与重大事件的接近度（Closeness to major events）\n    + 硬编码类别特征，如：date_3_days_before_holidays = 1\n    + 尝试：国庆节，重大体育赛事，周末，一个月的第一个星期六等\n    + 这些因素可能对支出行为产生重大影响\n\n#### 空间特征（Spatial Variables）\n* 特点\n  - 空间变量是在空间编码的位置的变量\n  - 例子包括：GPS坐标，城市，国家，地址\n* 方法\n  - 分类位置（Categorizing location）\n    + 克里金法（Kriging）\n    + K-means聚类\n    + 原始纬度经度\n    + 将城市转换为纬度经度\n    + 将邮政编码添加到街道名称\n  - 与枢纽的接近度（Closeness to Hubs）\n    + 找到位置与主要枢纽之间的紧密程度\n    + 小城镇继承了附近大城市的一些文化/背景\n    + 电话位置可以映射到附近的企业和超市\n  - 空间欺诈行为（Spatial fraudulent behavior）\n    + 位置事件数据可以指示可疑行为\n    + 不可能的旅行速度：不同国家的多个同步交易\n    + 在不同的城镇消费，而不是在家或送货地址\n    + 永远不要在同一地点消费\n  - 探索（Exploration）\n    + 数据探索可以发现数据健康问题，异常值，噪声，特征工程想法，特征清洗想法\n    + 可以使用：Console, Notebook, Pandas\n    + 尝试简单的统计数据：最小值，最大值\n    + 将目标结合起来，以便在信息之间找到相关性\n  - 迭代/调试（Iteration / Debugging）\n    + 特征工程是一个迭代过程：使你的pipelines适合快速迭代\n    + 使用子线性调试：输出有关过程的中间信息，进行伪log\n    + 使用允许快速实验的工具\n    + 失败的想法会多余成功的想法\n  - 标签工程（Label Engineering）\n    + 可以将标签/目标/因变量视为数据的一个特征，反之亦然\n    + 对数变换：y  - > log（y + 1）| exp（y_pred） -  1\n    + Square 变换\n    + Box-Cox变换\n    + 创建分数，在回归中转换二进制目标\n    + 训练回归器以预测测试集中不可用的特征\n\n#### 自然语言处理（Natural Language Processing）\n* 特点\n  - 可以用类别特征中相同的方法\n  - 深度学习（自动特征工程）正在慢慢的吞噬这个领域，但是具有好的特征工程的浅学习仍然具有竞争力\n  - 高稀疏性的数据将带来“维度诅咒”\n  - 特征工程具有很多机会\n* 方法\n  - 所有方法列表\n    + 转换成小写字母\n    + 删除非字母数字\n    + 修复\n    + 编码标点符号\n    + 符号化\n    + 令牌克（Token-grams）\n    + skipgrams\n    + char-grams\n    + 删除停用词\n    + 删除罕见的单词\n    + 非常常见的词\n    + 拼写纠正\n    + 砍字\n    + 词干\n    + 词形还原\n    + 文档特征\n    + 实体的插入和提取\n    + 简化\n    + Word2Vec 和 GloVe / Doc2Vec\n    + 字符串相似性\n    + 阅读水平\n    + 最近邻居\n    + TF*IDF\n    + BayesSVM，矢量化，LDA，LSA\n  - 清洗（Cleaning）\n    + 转换成小写字母：使标记独立于大写：“I work at NASA” -> “i work at nasa”.\n    + 转换成Unidecode：将字符转换为ascii-对应物：\n    + 删除非字母数字：删除不在[a-z] [A-Z] [0-9]中的任何内容来清理文本，“Breaking! Amsterdam (2009)” -> “Breaking Amsterdam 2009”\n    + 修复：修复编码问题或修剪intertoken空格。 “C a s a C a f＆eacute;” - >“CasaCafé”\n  - 符号化（Tokenizing）\n    + 编码标点符号：硬编码“！”和“？”作为标记。\n    + 符号化（Tokenize）：划分句子标记成单词记号\n    + N-Grams：将连续的符号编码为符号,  “I like the Beatles” -> [“I like”, “like the”, “the Beatles”]\n    + Skip-grams: 编码连续的符号，但跳过一些,  “I like the Beatles” -> [“I the”, “like Beatles”]\n    + Char-grams: 与N-gram相同，但字符级别, “Beatles” - > [“Bea”, “eat”, “atl”, “tle”, “les”]\n    + Affixes：与char-gram相同，但是仅限于前缀与后缀\n  - 删除（Removing）\n    + 停用词：删除停用词列表中出现的单词/标记\n    + 稀有单词：删除仅在训练集中出现几次的单词\n    + 常用词：删除可能不在停用词列表中的极其常见的词\n  - 根（Roots）\n    + 拼写纠正：将字符更改为正确的拼写\n    + 切（chop）： 仅取一个单词的前n（8）个字符\n    + 词干：将词/标记减少到其根， “cars” -> “car”\n    + Lemmatize：找到语义根， “never be late” -> “never are late”\n  - 丰富（Enrich）\n    + 文档特征：计算空格数量，tab数量，换行数量，字符数量，以及令牌数量等\n    + 实体插入：向文本中插入更多的通用的规范， “Microsoft releases Windows” -> “Microsoft (company) releases Windows (application)”\n    + 解析树：将句子解析为逻辑形式，“Alice hits Bill” -> Alice/Noun_subject hits/Verb Bill/Noun_object.\n    + 阅读级别：计算文档的阅读级别\n  - 相似性（Similarities）\n    + 令牌相似性：计算出现在两个文本中的令牌数\n    + 压缩距离：查看是否可以使用其他文本更好地压缩一个文本\n    + Levenshtein / Hamming / Jaccard 距离：通过查看在另一个字符串中转换一个字符串所需的操作数来检查两个字符串之间的相似性\n    + Word2Vec / Glove：检查两个平均向量之间的余弦相似度\n  - TF-IDF\n    + 术语频率：减少对长文档的偏差\n    + 反向文档频率：减少对常见令牌的偏差\n    + TF-IDF：用于标识文档中最重要的标记，删除不重要的标记，或作为降维的预处理步骤\n  - 降维\n    + PCA：将文本缩小为50或100维向量\n    + SVD：将文本缩小为50或100维向量\n    + LDA：TF-IDF，然后是SVD\n    + LSA：创建主题向量\n  - 外部模型\n    + 情绪分析器：为任何文本获取负面或正面情绪的向量\n    + 主题模型：使用另一个数据集为新数据集创建主题向量\n#### 深度学习/神经网络\n* 神经网络声称是端到端的自动特征工程。所以特征工程没用了么？并不是这样的。特征工程将重点转移到架构工程。\n* 尽管承诺：计算机视觉使用的特征， 例如：\n  - HOG\n  - SIFT\n  - whitening\n  - perturbation\n  - image pyramids\n  - rotation\n  - z-scaling\n  - log-scaling\n  - frame- grams\n  - external semantic data\n  - ...\n\n#### Leakage / Golden Features\n* 特征工程可以帮助利用泄露\n* 逆向工程\n  - 使用rainbow表反转 MD5 Hash\n  - 将 TF-IDF反转回术语频率\n  - 编码样本数据集的顺序\n  - 编码文件创建日期\n* 规则挖掘\n  - 查找简单的规则（并对其进行编码）以帮助您的模型\n\n<!-- $$\nf(n) = \\begin{cases}\n \\frac{n}{2},\n & \\text{if } n\\text{ is even}\n \\\\ 3n+1, & \\text{if } n\\text{ is odd}\n \\end{cases}\n$$ -->\n\n\n### 参考资料\n[Tips & Tricks for Feature Engineering / Applied Machine Learning](https://www.slideshare.net/HJvanVeen/feature-engineering-72376750)\n[]","source":"_posts/2019-07-29-特征工程.md","raw":"---\ntitle: \"特征工程\"\ncatalog: true\ntoc_nav_num: true\n# mathjax: true\ndate: 2019-07-29 18:30:24\nsubtitle:\nheader-img: \"/img/article_header/article_header.png\"\ntags:\n- 特征工程\ncatagories:\n- 机器学习\n\n---\n\n> 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已\n> 实践中学习的手艺\n> More data beats clever algorithms, but better data beats more data\n\n### 特征工程包含以下几个方面：\n#### 特征使用方案\n* 要实现我们的目标需要哪些数据？\n  - 基于业务理解，尽可能找出对因变量有影响的所有自变量\n* 可用性评估\n  - 获取难度\n  - 覆盖率\n  - 准确率\n\n#### 特征获取方案\n* 如何获取这些特征？\n* 如何存储？\n\n#### 特征处理\n* 特征特征清洗\n  - 清洗异样样本\n  - 采样\n    + 数据不均衡\n    + 样本权重\n* 预处理\n  - 单个特征\n    + 归一化\n    + 离散化\n    + Dummy Coding\n    + 缺失值\n    + 数据变换\n      - log\n      - 指数\n      - Box-Cox\n  - 多个特征\n    + Filter\n      - 思路：自变量和目标变量之间的关联\n      - 相关系数\n      - 卡方检验\n      - 信息增益、 互信息\n    + Wrapper\n      - 思路: 通过目标函数（AUC/MSE）来决定是否加入一个变量\n      - 迭代：产生特征子集，评价\n        + 完全搜索\n        + 启发式搜索\n        + 随机搜索\n          - GA\n          - SA\n    + Embedded\n      - 思路：学习期自身自动选择特征\n      - 正则化\n        + L1 -- Lasso\n        + L2 -- Ridge\n      - 决策树 -- 熵、信息增益\n      - 深度学习\n  - 衍生变量 -- 对原始数据加工，生成有商业意义的变量\n\n#### 特征监控\n* 特征有效性分析\n* 特征监控\n\n### 最基本的特征工程方法\n#### 类别特征\n  * 特点\n    - 几乎总是需要一些处理\n    - 高基数可以创建非常稀疏的数据\n    - 很难插补缺失数据\n  * 方法\n    - 独热编码（One-Hot Encoding）\n      + 概念\n        - 在长度为K的数组上做 one-of-k 编码\n        - 基本方法： 与大多数线性算法一起使用\n        - 删除第一列可以避免多重共线性\n        - 稀疏格式对内存友好\n        - 当前大多数实现都没有处理缺失，看不见的数据\n      + 例子\n        - ['BR']\n          | 国家  =>|国家=NL  | 国家=BR  | 国家=US  |\n          |---|---|---|---|---|---|\n          |  NL | |||\n          |  BR | [   0|   1|   0]|\n          |  US |   |||\n        - 编码集：[0, 1, 0]\n        - 编码稀疏： 2:1\n    - 散列编码（Hash encoding)\n      + 概念\n        - 独热编码是否具有固定长度的数组？\n        - 避免极其稀疏的数据\n        - 可能会引入碰撞\n        - 可以重复的使用不同的哈希函数和包获得小的精度\n        - 碰撞通常会降低结果，但可能会改善结果\n        - 优雅地处理新变量（例如：新用户代理）\n      + 例子\n        - ['BR']\n        - hash('BR') =>\n          | 国家  | hash1  | hash2 | hash3  | hash4| hash5|\n          |---|---|---|---|---|---|\n          |  NL |   |   |   |   ||\n          |  BR |[   0|   1|   0|   0| 0]|\n          |  US |   |   |   |   ||\n        - 编码集：[0, 1, 0, 0, 0]\n        - 编码稀疏： 2:1\n\n    - 标签编码（Label encoding）\n      + 概念\n        - 为每个类别变量提供唯一的数字ID\n        - 对于非线性基于树的算法很有用\n        - 不增加维度\n        - 随机化类别变量到数值变量的映射并重新训练， 平均以获得精度较小的凸凹\n      + 例子\n        - ['Queenstown']\n          | 城市  =>| city  |\n          |---|---|\n          |  Cherbourg |  1 |\n          |  Queenstown |  2 |\n          |  Southhampton |  3 |\n        - 编码： [2]\n    - 计数编码（Count encoding）\n      + 概念\n        - 将类别变量替换为他们在训练数据中的计数\n        - 适用于线性和非线性算法\n        - 可以对异常值敏感\n        - 可以加入对数转换（log transform）, 与计数一起工作的很好\n        - 用‘1’替换看不见的数据\n        - 可能会发生冲突：相同的编码，不同的变量\n      + 例子\n        - ['A6GHBD78']\n          | teacher_id  |   teacher_id|\n          |---|---|---|\n          |  DEADB33F |   4|\n          |  A6GHBD78|   3|\n          |  DEADB33F |   4|\n          |  FCKGWRHQ |   1|\n          |  DEADB33F |   4|\n          |  A6GHBD78|   3|\n          |  A6GHBD78|   3|\n          |  DEADB33F |   4|\n        - 编码： [3]\n    - 标签计数编码（LabelCount encoding）\n      + 概念\n        - 在训练数据中，对类别变量进行排名\n        - 适用于线性和非线性算法\n        - 对异常值不敏感\n        - 不会对不同的变量赋予相同的编码\n        - 两全其美\n      + 例子\n        - ['nl']\n          | tld  |   tld|\n          |---|---|---|\n          |  nl |   3|\n          |  nl|   3|\n          |  nl |   3|\n          |  nl |   3|\n          |  de |   2|\n          |  de|   2|\n          |  fr|   1|\n          |  fr |   1|\n        - 编码： [3]\n    - Target encoding\n      + 概念\n        - 根据目标比率对类别变量进行编码（二进制分类或回归）\n        - 小心避免过度拟合（overfit）\n        - 堆叠的形式：单变量模型，其输出平均目标\n        - 以交叉验证方式进行\n        - 添加平滑以避免将变量编码设置为0\n        - 添加随机噪音以对抗过拟合\n        - 什么时候用：线性和非线性的最佳编码\n      + 例子\n        | role  |  y |  role |\n        |---|---|---|---|---|\n        |  manager |  1 |  0.5 |\n        |  engineer |  1 |   0.66|\n        |  scientist |  1 |   1.|\n        | manager| 0|0.5|\n        | engineer|0|0.66|\n        | engineer|1|0.66|\n\n    - 类别嵌入（Category Embedding）\n      + 概念\n        - 使用神经网络从类别变量创建密集嵌入\n        - 将函数逼近问题中的类别变量映射到欧几里德空间\n        - 更快的模型训练\n        - 减少内存开销\n        - 可以提供比1-hot 编码更好的精准度\n      + 例子\n        | role  |  role 3-D embedding |\n        |---|---|\n        |  manager |  [0.05, 0.10, 0.96] |\n        |  engineer | [0.72, 0.66, 0.17]|\n        |  scientist |  [0.75, 0.62, 0.15]|\n        | manager| [0.05, 0.10, 0.96]|\n        | engineer|[0.72, 0.66, 0.17]|\n        | engineer|[0.72, 0.66, 0.17]|\n\n    - NaN编码（NaN encoding）\n      + 概念\n        - 为NaN值提供显式编码而不是忽略\n        - NaN值可以保存信息\n        - 小心避免过度拟合\n        - 仅在训练数据和测试数据中的Nan值是由相同的原因引起时才可以用，或者本地验证证明它持有信息\n      + 例子\n        - ['NaN']\n          | UA | UA=mobile| UA=tablet| UA=NaN|\n          |---|---|---|---|\n          |mobile| |||\n          |tablet||||\n          |mobile||||\n          |NaN|0|0|1|\n          |mobile||||\n        - 编码： [0, 0, 1]\n\n    - 多项式编码（Polynomial encoding）\n      + 概念\n        - 类别变量之间的编码交互\n        - 没有交互的线性算法无法解决XOR问题\n        - 多项式内核可以解决XOR问题\n        - 爆炸式的特征空间： 使用FS，散列或者VW\n      + 例子\n        |A  |B  |y  | A=1*B=1| A=0*B=1| A=1*B=0 | A=0*B=0| y|\n        |---|---|---|---|---|---|---|---|\n        |1  |1  | 1 | 1|   0|  0|0|1 |\n        |0  |1  | 0 | 0|   1|  0|0|0 |\n        |1  |0  | 0 | 0|   0|  1|0|0 |\n        |0  |0  | 1 | 0|   0|  0|1|1 |\n    - 扩展编码（Expansion encoding）\n      + 概念\n        - 从单个变量创建多个类别变量\n        - 某些高基数功能（如用户代理）在其中包含更多信息：\n          + is_mobile?\n          + is_latest_version?\n          + Operation_system\n          + Browser_build\n          + etc...\n      + 例子\n        - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\n          ==>\n          |UA1|UA2|UA3|UA4|UA5|\n          |---|---|---|---|---|\n          |Chrome|53.0.2785.143|Desktop|Mac|10_10_4|\n    - 合并编码（Consolidation encoding）\n      + 概念\n        - 将不同的类别变量映射到同一个变量\n        - 拼写错误，略有不同的职位描述，全名 vs 缩写\n        - 真实数据很乱，自由文本尤其如此\n      + 例子\n        |company_desc   =>| desc1| company_desc2|\n        |---------------|------|--------------|\n        |Shell          | Shell|Gas station|\n        |shel           | Shell|Gas station|\n        |SHELL          | Shell|Gas station|\n        |Shell Gasonline| Shell|Gas station|\n        |BP             | BP| Gas station|\n        |British Petr. | BP | Gas station|\n        |B&P           | BP | Gas station|\n        |BP Gas Station| BP| Gas station|\n        |bp            | BP | Gas station|\n        |Procter&Gamble| P&G| Manufacturer|\n#### 数值特征\n* 特点\n  - 可以更容易地输入算法\n  - 可以构成浮点数，计数，数字\n  - 更容易估算缺失的数据\n* 方法\n  - 四舍五入（Rounding）\n    + 概念\n      - 四舍五入数值变量\n      - 有损压缩： 保留数据的最重要特征\n      - 有时太精确只是噪音\n      - 四舍五入的变量可以视为类别变量\n      - 可以在四舍五入之前做对数变换\n    + 例子\n      |age | age1|age2|\n      |---|---|---|\n      |23.6671| 23|2|\n      |23.8891|23|2|\n      |22.1261|22|2|\n      |19.5506|19|1|\n      |18.2114|18|1|\n  - 分档（Binning）\n    + 概念\n      - 将数值变量放入bin（档）中并使用bin-ID进行编码\n      - 分档可以务实设置，通过分位数，均匀的，或使用模型到最佳分档\n      - 可以使得训练集所见范围以外的变量正常工作\n    + 例子\n      |risk_score| rs[-inf, 33]| rs[33,66]|rs[66,inf]|\n      |---|---|---|---|\n      |15| 1|0|0|\n      |77|0|0|1|\n      |78|0|0|1|\n      |55|0|1|0|\n      |42|0|1|0|\n  - 缩放（Scaling）\n    + 概念\n      - 将数值变量扩展到特定范围\n      - Standard（Z）缩放\n      - MinMax 缩放\n      - Root 缩放\n      - Log 缩放\n  - 估算（Imputation）\n    + 概念\n      - 估算缺失的变量\n      - 硬编码可与估算相结合\n      - 平均：非常基本的\n      - 中位数：对异常值鲁棒性比较高\n      - 忽略： 只是推迟问题\n      - 使用模型：可以暴露算法的偏差\n    + 例子\n      |wage|hours|gender|y => | wage|hours|gender_y|\n      |---|---|---|---|---|---|---|\n      |1600|40|0|1|1600|40|0|\n      |2200|50|1|1|2200|50|1|\n      |1800|36|0|0|1800|36|0|\n      |2100|45|1|0|2100|45|?|\n      |2050|60|NaN|0|2050|60|?|\n      |1650|36|0|1|1650|36|?|\n  - 相互作用（Interactions）\n    + 概念\n      - 具体来说编码数值变量之间的相互作用\n      - 尝试：减法，加法，乘法，除法\n      - 使用：通过统 计测试选择特征，或训练模型特征重要性\n      - 忽略：人的直觉; 奇怪的相互作用可以带来显著的改进\n  - 线性算法的非线性编码（No-linear encoding for linear algo's）\n    + 概念\n      - 硬编码非线性以改进线性算法\n      - 多项式内核\n      - 叶编码（随机森林嵌入）\n      - 遗传算法\n      - 局部线性嵌入，光谱嵌入，t-SNE\n  - 行统计（Row statistics）\n    + 概念\n      - 创建一行数据的统计信息\n      - NaN的数量\n      - 0的数量\n      - 负数值的数量\n      - 平均值，最大值，最小值，偏度 等\n#### 时间特征 (Temporal variables)\n* 特点\n  - 时间变量，如日期，需要更好的本地验证方案（如回测）\n  - 容易在这里犯错误\n  - 很多机会进行重大改进\n* 方法\n  - 投射到一个圆\n    + 将单个要素（如day_of_week）转换为圆上的两个坐标\n    + 确保max和min之间的距离与min和min +1相同\n    + 用于day_of_week，day_of_month，hour_of_day等\n  - 趋势线（Trendlines）\n    + 不是编码总支出，而是编码上周花费，上个月花费，去年花费。\n    + 给算法的趋势：两个支出相同的客户可能会有截然不同的行为 - 一个客户可能开始花费更多，而另一个客户开始减少支出。\n  - 与重大事件的接近度（Closeness to major events）\n    + 硬编码类别特征，如：date_3_days_before_holidays = 1\n    + 尝试：国庆节，重大体育赛事，周末，一个月的第一个星期六等\n    + 这些因素可能对支出行为产生重大影响\n\n#### 空间特征（Spatial Variables）\n* 特点\n  - 空间变量是在空间编码的位置的变量\n  - 例子包括：GPS坐标，城市，国家，地址\n* 方法\n  - 分类位置（Categorizing location）\n    + 克里金法（Kriging）\n    + K-means聚类\n    + 原始纬度经度\n    + 将城市转换为纬度经度\n    + 将邮政编码添加到街道名称\n  - 与枢纽的接近度（Closeness to Hubs）\n    + 找到位置与主要枢纽之间的紧密程度\n    + 小城镇继承了附近大城市的一些文化/背景\n    + 电话位置可以映射到附近的企业和超市\n  - 空间欺诈行为（Spatial fraudulent behavior）\n    + 位置事件数据可以指示可疑行为\n    + 不可能的旅行速度：不同国家的多个同步交易\n    + 在不同的城镇消费，而不是在家或送货地址\n    + 永远不要在同一地点消费\n  - 探索（Exploration）\n    + 数据探索可以发现数据健康问题，异常值，噪声，特征工程想法，特征清洗想法\n    + 可以使用：Console, Notebook, Pandas\n    + 尝试简单的统计数据：最小值，最大值\n    + 将目标结合起来，以便在信息之间找到相关性\n  - 迭代/调试（Iteration / Debugging）\n    + 特征工程是一个迭代过程：使你的pipelines适合快速迭代\n    + 使用子线性调试：输出有关过程的中间信息，进行伪log\n    + 使用允许快速实验的工具\n    + 失败的想法会多余成功的想法\n  - 标签工程（Label Engineering）\n    + 可以将标签/目标/因变量视为数据的一个特征，反之亦然\n    + 对数变换：y  - > log（y + 1）| exp（y_pred） -  1\n    + Square 变换\n    + Box-Cox变换\n    + 创建分数，在回归中转换二进制目标\n    + 训练回归器以预测测试集中不可用的特征\n\n#### 自然语言处理（Natural Language Processing）\n* 特点\n  - 可以用类别特征中相同的方法\n  - 深度学习（自动特征工程）正在慢慢的吞噬这个领域，但是具有好的特征工程的浅学习仍然具有竞争力\n  - 高稀疏性的数据将带来“维度诅咒”\n  - 特征工程具有很多机会\n* 方法\n  - 所有方法列表\n    + 转换成小写字母\n    + 删除非字母数字\n    + 修复\n    + 编码标点符号\n    + 符号化\n    + 令牌克（Token-grams）\n    + skipgrams\n    + char-grams\n    + 删除停用词\n    + 删除罕见的单词\n    + 非常常见的词\n    + 拼写纠正\n    + 砍字\n    + 词干\n    + 词形还原\n    + 文档特征\n    + 实体的插入和提取\n    + 简化\n    + Word2Vec 和 GloVe / Doc2Vec\n    + 字符串相似性\n    + 阅读水平\n    + 最近邻居\n    + TF*IDF\n    + BayesSVM，矢量化，LDA，LSA\n  - 清洗（Cleaning）\n    + 转换成小写字母：使标记独立于大写：“I work at NASA” -> “i work at nasa”.\n    + 转换成Unidecode：将字符转换为ascii-对应物：\n    + 删除非字母数字：删除不在[a-z] [A-Z] [0-9]中的任何内容来清理文本，“Breaking! Amsterdam (2009)” -> “Breaking Amsterdam 2009”\n    + 修复：修复编码问题或修剪intertoken空格。 “C a s a C a f＆eacute;” - >“CasaCafé”\n  - 符号化（Tokenizing）\n    + 编码标点符号：硬编码“！”和“？”作为标记。\n    + 符号化（Tokenize）：划分句子标记成单词记号\n    + N-Grams：将连续的符号编码为符号,  “I like the Beatles” -> [“I like”, “like the”, “the Beatles”]\n    + Skip-grams: 编码连续的符号，但跳过一些,  “I like the Beatles” -> [“I the”, “like Beatles”]\n    + Char-grams: 与N-gram相同，但字符级别, “Beatles” - > [“Bea”, “eat”, “atl”, “tle”, “les”]\n    + Affixes：与char-gram相同，但是仅限于前缀与后缀\n  - 删除（Removing）\n    + 停用词：删除停用词列表中出现的单词/标记\n    + 稀有单词：删除仅在训练集中出现几次的单词\n    + 常用词：删除可能不在停用词列表中的极其常见的词\n  - 根（Roots）\n    + 拼写纠正：将字符更改为正确的拼写\n    + 切（chop）： 仅取一个单词的前n（8）个字符\n    + 词干：将词/标记减少到其根， “cars” -> “car”\n    + Lemmatize：找到语义根， “never be late” -> “never are late”\n  - 丰富（Enrich）\n    + 文档特征：计算空格数量，tab数量，换行数量，字符数量，以及令牌数量等\n    + 实体插入：向文本中插入更多的通用的规范， “Microsoft releases Windows” -> “Microsoft (company) releases Windows (application)”\n    + 解析树：将句子解析为逻辑形式，“Alice hits Bill” -> Alice/Noun_subject hits/Verb Bill/Noun_object.\n    + 阅读级别：计算文档的阅读级别\n  - 相似性（Similarities）\n    + 令牌相似性：计算出现在两个文本中的令牌数\n    + 压缩距离：查看是否可以使用其他文本更好地压缩一个文本\n    + Levenshtein / Hamming / Jaccard 距离：通过查看在另一个字符串中转换一个字符串所需的操作数来检查两个字符串之间的相似性\n    + Word2Vec / Glove：检查两个平均向量之间的余弦相似度\n  - TF-IDF\n    + 术语频率：减少对长文档的偏差\n    + 反向文档频率：减少对常见令牌的偏差\n    + TF-IDF：用于标识文档中最重要的标记，删除不重要的标记，或作为降维的预处理步骤\n  - 降维\n    + PCA：将文本缩小为50或100维向量\n    + SVD：将文本缩小为50或100维向量\n    + LDA：TF-IDF，然后是SVD\n    + LSA：创建主题向量\n  - 外部模型\n    + 情绪分析器：为任何文本获取负面或正面情绪的向量\n    + 主题模型：使用另一个数据集为新数据集创建主题向量\n#### 深度学习/神经网络\n* 神经网络声称是端到端的自动特征工程。所以特征工程没用了么？并不是这样的。特征工程将重点转移到架构工程。\n* 尽管承诺：计算机视觉使用的特征， 例如：\n  - HOG\n  - SIFT\n  - whitening\n  - perturbation\n  - image pyramids\n  - rotation\n  - z-scaling\n  - log-scaling\n  - frame- grams\n  - external semantic data\n  - ...\n\n#### Leakage / Golden Features\n* 特征工程可以帮助利用泄露\n* 逆向工程\n  - 使用rainbow表反转 MD5 Hash\n  - 将 TF-IDF反转回术语频率\n  - 编码样本数据集的顺序\n  - 编码文件创建日期\n* 规则挖掘\n  - 查找简单的规则（并对其进行编码）以帮助您的模型\n\n<!-- $$\nf(n) = \\begin{cases}\n \\frac{n}{2},\n & \\text{if } n\\text{ is even}\n \\\\ 3n+1, & \\text{if } n\\text{ is odd}\n \\end{cases}\n$$ -->\n\n\n### 参考资料\n[Tips & Tricks for Feature Engineering / Applied Machine Learning](https://www.slideshare.net/HJvanVeen/feature-engineering-72376750)\n[]","slug":"2019-07-29-特征工程","published":1,"updated":"2019-07-30T09:28:43.546Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjysio1q00001chov15vtufud","content":"<blockquote>\n<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已<br>\n实践中学习的手艺<br>\nMore data beats clever algorithms, but better data beats more data</p>\n</blockquote>\n<h3 id=\"特征工程包含以下几个方面\"><a class=\"markdownIt-Anchor\" href=\"#特征工程包含以下几个方面\"></a> 特征工程包含以下几个方面：</h3>\n<h4 id=\"特征使用方案\"><a class=\"markdownIt-Anchor\" href=\"#特征使用方案\"></a> 特征使用方案</h4>\n<ul>\n<li>要实现我们的目标需要哪些数据？\n<ul>\n<li>基于业务理解，尽可能找出对因变量有影响的所有自变量</li>\n</ul>\n</li>\n<li>可用性评估\n<ul>\n<li>获取难度</li>\n<li>覆盖率</li>\n<li>准确率</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"特征获取方案\"><a class=\"markdownIt-Anchor\" href=\"#特征获取方案\"></a> 特征获取方案</h4>\n<ul>\n<li>如何获取这些特征？</li>\n<li>如何存储？</li>\n</ul>\n<h4 id=\"特征处理\"><a class=\"markdownIt-Anchor\" href=\"#特征处理\"></a> 特征处理</h4>\n<ul>\n<li>特征特征清洗\n<ul>\n<li>清洗异样样本</li>\n<li>采样\n<ul>\n<li>数据不均衡</li>\n<li>样本权重</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>预处理\n<ul>\n<li>单个特征\n<ul>\n<li>归一化</li>\n<li>离散化</li>\n<li>Dummy Coding</li>\n<li>缺失值</li>\n<li>数据变换\n<ul>\n<li>log</li>\n<li>指数</li>\n<li>Box-Cox</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>多个特征\n<ul>\n<li>Filter\n<ul>\n<li>思路：自变量和目标变量之间的关联</li>\n<li>相关系数</li>\n<li>卡方检验</li>\n<li>信息增益、 互信息</li>\n</ul>\n</li>\n<li>Wrapper\n<ul>\n<li>思路: 通过目标函数（AUC/MSE）来决定是否加入一个变量</li>\n<li>迭代：产生特征子集，评价\n<ul>\n<li>完全搜索</li>\n<li>启发式搜索</li>\n<li>随机搜索\n<ul>\n<li>GA</li>\n<li>SA</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Embedded\n<ul>\n<li>思路：学习期自身自动选择特征</li>\n<li>正则化\n<ul>\n<li>L1 – Lasso</li>\n<li>L2 – Ridge</li>\n</ul>\n</li>\n<li>决策树 – 熵、信息增益</li>\n<li>深度学习</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>衍生变量 – 对原始数据加工，生成有商业意义的变量</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"特征监控\"><a class=\"markdownIt-Anchor\" href=\"#特征监控\"></a> 特征监控</h4>\n<ul>\n<li>特征有效性分析</li>\n<li>特征监控</li>\n</ul>\n<h3 id=\"最基本的特征工程方法\"><a class=\"markdownIt-Anchor\" href=\"#最基本的特征工程方法\"></a> 最基本的特征工程方法</h3>\n<h4 id=\"类别特征\"><a class=\"markdownIt-Anchor\" href=\"#类别特征\"></a> 类别特征</h4>\n<ul>\n<li>特点\n<ul>\n<li>几乎总是需要一些处理</li>\n<li>高基数可以创建非常稀疏的数据</li>\n<li>很难插补缺失数据</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>\n<p>独热编码（One-Hot Encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>在长度为K的数组上做 one-of-k 编码</li>\n<li>基本方法： 与大多数线性算法一起使用</li>\n<li>删除第一列可以避免多重共线性</li>\n<li>稀疏格式对内存友好</li>\n<li>当前大多数实现都没有处理缺失，看不见的数据</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘BR’]\n<table>\n<thead>\n<tr>\n<th>国家  =&gt;</th>\n<th>国家=NL</th>\n<th>国家=BR</th>\n<th>国家=US</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NL</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>BR</td>\n<td>[   0</td>\n<td>1</td>\n<td>0]</td>\n</tr>\n<tr>\n<td>US</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码集：[0, 1, 0]</li>\n<li>编码稀疏： 2:1</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>散列编码（Hash encoding)</p>\n<ul>\n<li>概念\n<ul>\n<li>独热编码是否具有固定长度的数组？</li>\n<li>避免极其稀疏的数据</li>\n<li>可能会引入碰撞</li>\n<li>可以重复的使用不同的哈希函数和包获得小的精度</li>\n<li>碰撞通常会降低结果，但可能会改善结果</li>\n<li>优雅地处理新变量（例如：新用户代理）</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘BR’]</li>\n<li>hash(‘BR’) =&gt;\n<table>\n<thead>\n<tr>\n<th>国家</th>\n<th>hash1</th>\n<th>hash2</th>\n<th>hash3</th>\n<th>hash4</th>\n<th>hash5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NL</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>BR</td>\n<td>[   0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0]</td>\n</tr>\n<tr>\n<td>US</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码集：[0, 1, 0, 0, 0]</li>\n<li>编码稀疏： 2:1</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>标签编码（Label encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>为每个类别变量提供唯一的数字ID</li>\n<li>对于非线性基于树的算法很有用</li>\n<li>不增加维度</li>\n<li>随机化类别变量到数值变量的映射并重新训练， 平均以获得精度较小的凸凹</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘Queenstown’]\n<table>\n<thead>\n<tr>\n<th>城市  =&gt;</th>\n<th>city</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Cherbourg</td>\n<td>1</td>\n</tr>\n<tr>\n<td>Queenstown</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Southhampton</td>\n<td>3</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [2]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>计数编码（Count encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>将类别变量替换为他们在训练数据中的计数</li>\n<li>适用于线性和非线性算法</li>\n<li>可以对异常值敏感</li>\n<li>可以加入对数转换（log transform）, 与计数一起工作的很好</li>\n<li>用‘1’替换看不见的数据</li>\n<li>可能会发生冲突：相同的编码，不同的变量</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘A6GHBD78’]\n<table>\n<thead>\n<tr>\n<th>teacher_id</th>\n<th>teacher_id</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n<tr>\n<td>A6GHBD78</td>\n<td>3</td>\n</tr>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n<tr>\n<td>FCKGWRHQ</td>\n<td>1</td>\n</tr>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n<tr>\n<td>A6GHBD78</td>\n<td>3</td>\n</tr>\n<tr>\n<td>A6GHBD78</td>\n<td>3</td>\n</tr>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [3]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>标签计数编码（LabelCount encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>在训练数据中，对类别变量进行排名</li>\n<li>适用于线性和非线性算法</li>\n<li>对异常值不敏感</li>\n<li>不会对不同的变量赋予相同的编码</li>\n<li>两全其美</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘nl’]\n<table>\n<thead>\n<tr>\n<th>tld</th>\n<th>tld</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>de</td>\n<td>2</td>\n</tr>\n<tr>\n<td>de</td>\n<td>2</td>\n</tr>\n<tr>\n<td>fr</td>\n<td>1</td>\n</tr>\n<tr>\n<td>fr</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [3]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Target encoding</p>\n<ul>\n<li>概念\n<ul>\n<li>根据目标比率对类别变量进行编码（二进制分类或回归）</li>\n<li>小心避免过度拟合（overfit）</li>\n<li>堆叠的形式：单变量模型，其输出平均目标</li>\n<li>以交叉验证方式进行</li>\n<li>添加平滑以避免将变量编码设置为0</li>\n<li>添加随机噪音以对抗过拟合</li>\n<li>什么时候用：线性和非线性的最佳编码</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>role</th>\n<th>y</th>\n<th>role</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>manager</td>\n<td>1</td>\n<td>0.5</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>1</td>\n<td>0.66</td>\n</tr>\n<tr>\n<td>scientist</td>\n<td>1</td>\n<td>1.</td>\n</tr>\n<tr>\n<td>manager</td>\n<td>0</td>\n<td>0.5</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>0</td>\n<td>0.66</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>1</td>\n<td>0.66</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>类别嵌入（Category Embedding）</p>\n<ul>\n<li>概念\n<ul>\n<li>使用神经网络从类别变量创建密集嵌入</li>\n<li>将函数逼近问题中的类别变量映射到欧几里德空间</li>\n<li>更快的模型训练</li>\n<li>减少内存开销</li>\n<li>可以提供比1-hot 编码更好的精准度</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>role</th>\n<th>role 3-D embedding</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>manager</td>\n<td>[0.05, 0.10, 0.96]</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>[0.72, 0.66, 0.17]</td>\n</tr>\n<tr>\n<td>scientist</td>\n<td>[0.75, 0.62, 0.15]</td>\n</tr>\n<tr>\n<td>manager</td>\n<td>[0.05, 0.10, 0.96]</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>[0.72, 0.66, 0.17]</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>[0.72, 0.66, 0.17]</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>NaN编码（NaN encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>为NaN值提供显式编码而不是忽略</li>\n<li>NaN值可以保存信息</li>\n<li>小心避免过度拟合</li>\n<li>仅在训练数据和测试数据中的Nan值是由相同的原因引起时才可以用，或者本地验证证明它持有信息</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘NaN’]\n<table>\n<thead>\n<tr>\n<th>UA</th>\n<th>UA=mobile</th>\n<th>UA=tablet</th>\n<th>UA=NaN</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>mobile</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>tablet</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>mobile</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>NaN</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>mobile</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [0, 0, 1]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>多项式编码（Polynomial encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>类别变量之间的编码交互</li>\n<li>没有交互的线性算法无法解决XOR问题</li>\n<li>多项式内核可以解决XOR问题</li>\n<li>爆炸式的特征空间： 使用FS，散列或者VW</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>A</th>\n<th>B</th>\n<th>y</th>\n<th>A=1*B=1</th>\n<th>A=0*B=1</th>\n<th>A=1*B=0</th>\n<th>A=0*B=0</th>\n<th>y</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>扩展编码（Expansion encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>从单个变量创建多个类别变量</li>\n<li>某些高基数功能（如用户代理）在其中包含更多信息：\n<ul>\n<li>is_mobile?</li>\n<li>is_latest_version?</li>\n<li>Operation_system</li>\n<li>Browser_build</li>\n<li>etc…</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36<br>\n==&gt;\n<table>\n<thead>\n<tr>\n<th>UA1</th>\n<th>UA2</th>\n<th>UA3</th>\n<th>UA4</th>\n<th>UA5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Chrome</td>\n<td>53.0.2785.143</td>\n<td>Desktop</td>\n<td>Mac</td>\n<td>10_10_4</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>合并编码（Consolidation encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>将不同的类别变量映射到同一个变量</li>\n<li>拼写错误，略有不同的职位描述，全名 vs 缩写</li>\n<li>真实数据很乱，自由文本尤其如此</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>company_desc   =&gt;</th>\n<th>desc1</th>\n<th>company_desc2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Shell</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>shel</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>SHELL</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>Shell Gasonline</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>BP</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>British Petr.</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>B&amp;P</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>BP Gas Station</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>bp</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>Procter&amp;Gamble</td>\n<td>P&amp;G</td>\n<td>Manufacturer</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数值特征\"><a class=\"markdownIt-Anchor\" href=\"#数值特征\"></a> 数值特征</h4>\n<ul>\n<li>特点\n<ul>\n<li>可以更容易地输入算法</li>\n<li>可以构成浮点数，计数，数字</li>\n<li>更容易估算缺失的数据</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>四舍五入（Rounding）\n<ul>\n<li>概念\n<ul>\n<li>四舍五入数值变量</li>\n<li>有损压缩： 保留数据的最重要特征</li>\n<li>有时太精确只是噪音</li>\n<li>四舍五入的变量可以视为类别变量</li>\n<li>可以在四舍五入之前做对数变换</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>age</th>\n<th>age1</th>\n<th>age2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>23.6671</td>\n<td>23</td>\n<td>2</td>\n</tr>\n<tr>\n<td>23.8891</td>\n<td>23</td>\n<td>2</td>\n</tr>\n<tr>\n<td>22.1261</td>\n<td>22</td>\n<td>2</td>\n</tr>\n<tr>\n<td>19.5506</td>\n<td>19</td>\n<td>1</td>\n</tr>\n<tr>\n<td>18.2114</td>\n<td>18</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>分档（Binning）\n<ul>\n<li>概念\n<ul>\n<li>将数值变量放入bin（档）中并使用bin-ID进行编码</li>\n<li>分档可以务实设置，通过分位数，均匀的，或使用模型到最佳分档</li>\n<li>可以使得训练集所见范围以外的变量正常工作</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>risk_score</th>\n<th>rs[-inf, 33]</th>\n<th>rs[33,66]</th>\n<th>rs[66,inf]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>15</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>77</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>78</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>55</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n<tr>\n<td>42</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>缩放（Scaling）\n<ul>\n<li>概念\n<ul>\n<li>将数值变量扩展到特定范围</li>\n<li>Standard（Z）缩放</li>\n<li>MinMax 缩放</li>\n<li>Root 缩放</li>\n<li>Log 缩放</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>估算（Imputation）\n<ul>\n<li>概念\n<ul>\n<li>估算缺失的变量</li>\n<li>硬编码可与估算相结合</li>\n<li>平均：非常基本的</li>\n<li>中位数：对异常值鲁棒性比较高</li>\n<li>忽略： 只是推迟问题</li>\n<li>使用模型：可以暴露算法的偏差</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>wage</th>\n<th>hours</th>\n<th>gender</th>\n<th>y =&gt;</th>\n<th>wage</th>\n<th>hours</th>\n<th>gender_y</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1600</td>\n<td>40</td>\n<td>0</td>\n<td>1</td>\n<td>1600</td>\n<td>40</td>\n<td>0</td>\n</tr>\n<tr>\n<td>2200</td>\n<td>50</td>\n<td>1</td>\n<td>1</td>\n<td>2200</td>\n<td>50</td>\n<td>1</td>\n</tr>\n<tr>\n<td>1800</td>\n<td>36</td>\n<td>0</td>\n<td>0</td>\n<td>1800</td>\n<td>36</td>\n<td>0</td>\n</tr>\n<tr>\n<td>2100</td>\n<td>45</td>\n<td>1</td>\n<td>0</td>\n<td>2100</td>\n<td>45</td>\n<td>?</td>\n</tr>\n<tr>\n<td>2050</td>\n<td>60</td>\n<td>NaN</td>\n<td>0</td>\n<td>2050</td>\n<td>60</td>\n<td>?</td>\n</tr>\n<tr>\n<td>1650</td>\n<td>36</td>\n<td>0</td>\n<td>1</td>\n<td>1650</td>\n<td>36</td>\n<td>?</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>相互作用（Interactions）\n<ul>\n<li>概念\n<ul>\n<li>具体来说编码数值变量之间的相互作用</li>\n<li>尝试：减法，加法，乘法，除法</li>\n<li>使用：通过统 计测试选择特征，或训练模型特征重要性</li>\n<li>忽略：人的直觉; 奇怪的相互作用可以带来显著的改进</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>线性算法的非线性编码（No-linear encoding for linear algo’s）\n<ul>\n<li>概念\n<ul>\n<li>硬编码非线性以改进线性算法</li>\n<li>多项式内核</li>\n<li>叶编码（随机森林嵌入）</li>\n<li>遗传算法</li>\n<li>局部线性嵌入，光谱嵌入，t-SNE</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>行统计（Row statistics）\n<ul>\n<li>概念\n<ul>\n<li>创建一行数据的统计信息</li>\n<li>NaN的数量</li>\n<li>0的数量</li>\n<li>负数值的数量</li>\n<li>平均值，最大值，最小值，偏度 等</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"时间特征-temporal-variables\"><a class=\"markdownIt-Anchor\" href=\"#时间特征-temporal-variables\"></a> 时间特征 (Temporal variables)</h4>\n<ul>\n<li>特点\n<ul>\n<li>时间变量，如日期，需要更好的本地验证方案（如回测）</li>\n<li>容易在这里犯错误</li>\n<li>很多机会进行重大改进</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>投射到一个圆\n<ul>\n<li>将单个要素（如day_of_week）转换为圆上的两个坐标</li>\n<li>确保max和min之间的距离与min和min +1相同</li>\n<li>用于day_of_week，day_of_month，hour_of_day等</li>\n</ul>\n</li>\n<li>趋势线（Trendlines）\n<ul>\n<li>不是编码总支出，而是编码上周花费，上个月花费，去年花费。</li>\n<li>给算法的趋势：两个支出相同的客户可能会有截然不同的行为 - 一个客户可能开始花费更多，而另一个客户开始减少支出。</li>\n</ul>\n</li>\n<li>与重大事件的接近度（Closeness to major events）\n<ul>\n<li>硬编码类别特征，如：date_3_days_before_holidays = 1</li>\n<li>尝试：国庆节，重大体育赛事，周末，一个月的第一个星期六等</li>\n<li>这些因素可能对支出行为产生重大影响</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"空间特征spatial-variables\"><a class=\"markdownIt-Anchor\" href=\"#空间特征spatial-variables\"></a> 空间特征（Spatial Variables）</h4>\n<ul>\n<li>特点\n<ul>\n<li>空间变量是在空间编码的位置的变量</li>\n<li>例子包括：GPS坐标，城市，国家，地址</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>分类位置（Categorizing location）\n<ul>\n<li>克里金法（Kriging）</li>\n<li>K-means聚类</li>\n<li>原始纬度经度</li>\n<li>将城市转换为纬度经度</li>\n<li>将邮政编码添加到街道名称</li>\n</ul>\n</li>\n<li>与枢纽的接近度（Closeness to Hubs）\n<ul>\n<li>找到位置与主要枢纽之间的紧密程度</li>\n<li>小城镇继承了附近大城市的一些文化/背景</li>\n<li>电话位置可以映射到附近的企业和超市</li>\n</ul>\n</li>\n<li>空间欺诈行为（Spatial fraudulent behavior）\n<ul>\n<li>位置事件数据可以指示可疑行为</li>\n<li>不可能的旅行速度：不同国家的多个同步交易</li>\n<li>在不同的城镇消费，而不是在家或送货地址</li>\n<li>永远不要在同一地点消费</li>\n</ul>\n</li>\n<li>探索（Exploration）\n<ul>\n<li>数据探索可以发现数据健康问题，异常值，噪声，特征工程想法，特征清洗想法</li>\n<li>可以使用：Console, Notebook, Pandas</li>\n<li>尝试简单的统计数据：最小值，最大值</li>\n<li>将目标结合起来，以便在信息之间找到相关性</li>\n</ul>\n</li>\n<li>迭代/调试（Iteration / Debugging）\n<ul>\n<li>特征工程是一个迭代过程：使你的pipelines适合快速迭代</li>\n<li>使用子线性调试：输出有关过程的中间信息，进行伪log</li>\n<li>使用允许快速实验的工具</li>\n<li>失败的想法会多余成功的想法</li>\n</ul>\n</li>\n<li>标签工程（Label Engineering）\n<ul>\n<li>可以将标签/目标/因变量视为数据的一个特征，反之亦然</li>\n<li>对数变换：y  - &gt; log（y + 1）| exp（y_pred） -  1</li>\n<li>Square 变换</li>\n<li>Box-Cox变换</li>\n<li>创建分数，在回归中转换二进制目标</li>\n<li>训练回归器以预测测试集中不可用的特征</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"自然语言处理natural-language-processing\"><a class=\"markdownIt-Anchor\" href=\"#自然语言处理natural-language-processing\"></a> 自然语言处理（Natural Language Processing）</h4>\n<ul>\n<li>特点\n<ul>\n<li>可以用类别特征中相同的方法</li>\n<li>深度学习（自动特征工程）正在慢慢的吞噬这个领域，但是具有好的特征工程的浅学习仍然具有竞争力</li>\n<li>高稀疏性的数据将带来“维度诅咒”</li>\n<li>特征工程具有很多机会</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>所有方法列表\n<ul>\n<li>转换成小写字母</li>\n<li>删除非字母数字</li>\n<li>修复</li>\n<li>编码标点符号</li>\n<li>符号化</li>\n<li>令牌克（Token-grams）</li>\n<li>skipgrams</li>\n<li>char-grams</li>\n<li>删除停用词</li>\n<li>删除罕见的单词</li>\n<li>非常常见的词</li>\n<li>拼写纠正</li>\n<li>砍字</li>\n<li>词干</li>\n<li>词形还原</li>\n<li>文档特征</li>\n<li>实体的插入和提取</li>\n<li>简化</li>\n<li>Word2Vec 和 GloVe / Doc2Vec</li>\n<li>字符串相似性</li>\n<li>阅读水平</li>\n<li>最近邻居</li>\n<li>TF*IDF</li>\n<li>BayesSVM，矢量化，LDA，LSA</li>\n</ul>\n</li>\n<li>清洗（Cleaning）\n<ul>\n<li>转换成小写字母：使标记独立于大写：“I work at NASA” -&gt; “i work at nasa”.</li>\n<li>转换成Unidecode：将字符转换为ascii-对应物：</li>\n<li>删除非字母数字：删除不在[a-z] [A-Z] [0-9]中的任何内容来清理文本，“Breaking! Amsterdam (2009)” -&gt; “Breaking Amsterdam 2009”</li>\n<li>修复：修复编码问题或修剪intertoken空格。 “C a s a C a f＆eacute;” - &gt;“CasaCafé”</li>\n</ul>\n</li>\n<li>符号化（Tokenizing）\n<ul>\n<li>编码标点符号：硬编码“！”和“？”作为标记。</li>\n<li>符号化（Tokenize）：划分句子标记成单词记号</li>\n<li>N-Grams：将连续的符号编码为符号,  “I like the Beatles” -&gt; [“I like”, “like the”, “the Beatles”]</li>\n<li>Skip-grams: 编码连续的符号，但跳过一些,  “I like the Beatles” -&gt; [“I the”, “like Beatles”]</li>\n<li>Char-grams: 与N-gram相同，但字符级别, “Beatles” - &gt; [“Bea”, “eat”, “atl”, “tle”, “les”]</li>\n<li>Affixes：与char-gram相同，但是仅限于前缀与后缀</li>\n</ul>\n</li>\n<li>删除（Removing）\n<ul>\n<li>停用词：删除停用词列表中出现的单词/标记</li>\n<li>稀有单词：删除仅在训练集中出现几次的单词</li>\n<li>常用词：删除可能不在停用词列表中的极其常见的词</li>\n</ul>\n</li>\n<li>根（Roots）\n<ul>\n<li>拼写纠正：将字符更改为正确的拼写</li>\n<li>切（chop）： 仅取一个单词的前n（8）个字符</li>\n<li>词干：将词/标记减少到其根， “cars” -&gt; “car”</li>\n<li>Lemmatize：找到语义根， “never be late” -&gt; “never are late”</li>\n</ul>\n</li>\n<li>丰富（Enrich）\n<ul>\n<li>文档特征：计算空格数量，tab数量，换行数量，字符数量，以及令牌数量等</li>\n<li>实体插入：向文本中插入更多的通用的规范， “Microsoft releases Windows” -&gt; “Microsoft (company) releases Windows (application)”</li>\n<li>解析树：将句子解析为逻辑形式，“Alice hits Bill” -&gt; Alice/Noun_subject hits/Verb Bill/Noun_object.</li>\n<li>阅读级别：计算文档的阅读级别</li>\n</ul>\n</li>\n<li>相似性（Similarities）\n<ul>\n<li>令牌相似性：计算出现在两个文本中的令牌数</li>\n<li>压缩距离：查看是否可以使用其他文本更好地压缩一个文本</li>\n<li>Levenshtein / Hamming / Jaccard 距离：通过查看在另一个字符串中转换一个字符串所需的操作数来检查两个字符串之间的相似性</li>\n<li>Word2Vec / Glove：检查两个平均向量之间的余弦相似度</li>\n</ul>\n</li>\n<li>TF-IDF\n<ul>\n<li>术语频率：减少对长文档的偏差</li>\n<li>反向文档频率：减少对常见令牌的偏差</li>\n<li>TF-IDF：用于标识文档中最重要的标记，删除不重要的标记，或作为降维的预处理步骤</li>\n</ul>\n</li>\n<li>降维\n<ul>\n<li>PCA：将文本缩小为50或100维向量</li>\n<li>SVD：将文本缩小为50或100维向量</li>\n<li>LDA：TF-IDF，然后是SVD</li>\n<li>LSA：创建主题向量</li>\n</ul>\n</li>\n<li>外部模型\n<ul>\n<li>情绪分析器：为任何文本获取负面或正面情绪的向量</li>\n<li>主题模型：使用另一个数据集为新数据集创建主题向量</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"深度学习神经网络\"><a class=\"markdownIt-Anchor\" href=\"#深度学习神经网络\"></a> 深度学习/神经网络</h4>\n<ul>\n<li>神经网络声称是端到端的自动特征工程。所以特征工程没用了么？并不是这样的。特征工程将重点转移到架构工程。</li>\n<li>尽管承诺：计算机视觉使用的特征， 例如：\n<ul>\n<li>HOG</li>\n<li>SIFT</li>\n<li>whitening</li>\n<li>perturbation</li>\n<li>image pyramids</li>\n<li>rotation</li>\n<li>z-scaling</li>\n<li>log-scaling</li>\n<li>frame- grams</li>\n<li>external semantic data</li>\n<li>…</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"leakage-golden-features\"><a class=\"markdownIt-Anchor\" href=\"#leakage-golden-features\"></a> Leakage / Golden Features</h4>\n<ul>\n<li>特征工程可以帮助利用泄露</li>\n<li>逆向工程\n<ul>\n<li>使用rainbow表反转 MD5 Hash</li>\n<li>将 TF-IDF反转回术语频率</li>\n<li>编码样本数据集的顺序</li>\n<li>编码文件创建日期</li>\n</ul>\n</li>\n<li>规则挖掘\n<ul>\n<li>查找简单的规则（并对其进行编码）以帮助您的模型</li>\n</ul>\n</li>\n</ul>\n<!-- $$\nf(n) = \\begin{cases}\n \\frac{n}{2},\n & \\text{if } n\\text{ is even}\n \\\\ 3n+1, & \\text{if } n\\text{ is odd}\n \\end{cases}\n$$ -->\n<h3 id=\"参考资料\"><a class=\"markdownIt-Anchor\" href=\"#参考资料\"></a> 参考资料</h3>\n<p><a href=\"https://www.slideshare.net/HJvanVeen/feature-engineering-72376750\" target=\"_blank\" rel=\"noopener\">Tips &amp; Tricks for Feature Engineering / Applied Machine Learning</a><br>\n[]</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已<br>\n实践中学习的手艺<br>\nMore data beats clever algorithms, but better data beats more data</p>\n</blockquote>\n<h3 id=\"特征工程包含以下几个方面\"><a class=\"markdownIt-Anchor\" href=\"#特征工程包含以下几个方面\"></a> 特征工程包含以下几个方面：</h3>\n<h4 id=\"特征使用方案\"><a class=\"markdownIt-Anchor\" href=\"#特征使用方案\"></a> 特征使用方案</h4>\n<ul>\n<li>要实现我们的目标需要哪些数据？\n<ul>\n<li>基于业务理解，尽可能找出对因变量有影响的所有自变量</li>\n</ul>\n</li>\n<li>可用性评估\n<ul>\n<li>获取难度</li>\n<li>覆盖率</li>\n<li>准确率</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"特征获取方案\"><a class=\"markdownIt-Anchor\" href=\"#特征获取方案\"></a> 特征获取方案</h4>\n<ul>\n<li>如何获取这些特征？</li>\n<li>如何存储？</li>\n</ul>\n<h4 id=\"特征处理\"><a class=\"markdownIt-Anchor\" href=\"#特征处理\"></a> 特征处理</h4>\n<ul>\n<li>特征特征清洗\n<ul>\n<li>清洗异样样本</li>\n<li>采样\n<ul>\n<li>数据不均衡</li>\n<li>样本权重</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>预处理\n<ul>\n<li>单个特征\n<ul>\n<li>归一化</li>\n<li>离散化</li>\n<li>Dummy Coding</li>\n<li>缺失值</li>\n<li>数据变换\n<ul>\n<li>log</li>\n<li>指数</li>\n<li>Box-Cox</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>多个特征\n<ul>\n<li>Filter\n<ul>\n<li>思路：自变量和目标变量之间的关联</li>\n<li>相关系数</li>\n<li>卡方检验</li>\n<li>信息增益、 互信息</li>\n</ul>\n</li>\n<li>Wrapper\n<ul>\n<li>思路: 通过目标函数（AUC/MSE）来决定是否加入一个变量</li>\n<li>迭代：产生特征子集，评价\n<ul>\n<li>完全搜索</li>\n<li>启发式搜索</li>\n<li>随机搜索\n<ul>\n<li>GA</li>\n<li>SA</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Embedded\n<ul>\n<li>思路：学习期自身自动选择特征</li>\n<li>正则化\n<ul>\n<li>L1 – Lasso</li>\n<li>L2 – Ridge</li>\n</ul>\n</li>\n<li>决策树 – 熵、信息增益</li>\n<li>深度学习</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>衍生变量 – 对原始数据加工，生成有商业意义的变量</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"特征监控\"><a class=\"markdownIt-Anchor\" href=\"#特征监控\"></a> 特征监控</h4>\n<ul>\n<li>特征有效性分析</li>\n<li>特征监控</li>\n</ul>\n<h3 id=\"最基本的特征工程方法\"><a class=\"markdownIt-Anchor\" href=\"#最基本的特征工程方法\"></a> 最基本的特征工程方法</h3>\n<h4 id=\"类别特征\"><a class=\"markdownIt-Anchor\" href=\"#类别特征\"></a> 类别特征</h4>\n<ul>\n<li>特点\n<ul>\n<li>几乎总是需要一些处理</li>\n<li>高基数可以创建非常稀疏的数据</li>\n<li>很难插补缺失数据</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>\n<p>独热编码（One-Hot Encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>在长度为K的数组上做 one-of-k 编码</li>\n<li>基本方法： 与大多数线性算法一起使用</li>\n<li>删除第一列可以避免多重共线性</li>\n<li>稀疏格式对内存友好</li>\n<li>当前大多数实现都没有处理缺失，看不见的数据</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘BR’]\n<table>\n<thead>\n<tr>\n<th>国家  =&gt;</th>\n<th>国家=NL</th>\n<th>国家=BR</th>\n<th>国家=US</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NL</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>BR</td>\n<td>[   0</td>\n<td>1</td>\n<td>0]</td>\n</tr>\n<tr>\n<td>US</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码集：[0, 1, 0]</li>\n<li>编码稀疏： 2:1</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>散列编码（Hash encoding)</p>\n<ul>\n<li>概念\n<ul>\n<li>独热编码是否具有固定长度的数组？</li>\n<li>避免极其稀疏的数据</li>\n<li>可能会引入碰撞</li>\n<li>可以重复的使用不同的哈希函数和包获得小的精度</li>\n<li>碰撞通常会降低结果，但可能会改善结果</li>\n<li>优雅地处理新变量（例如：新用户代理）</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘BR’]</li>\n<li>hash(‘BR’) =&gt;\n<table>\n<thead>\n<tr>\n<th>国家</th>\n<th>hash1</th>\n<th>hash2</th>\n<th>hash3</th>\n<th>hash4</th>\n<th>hash5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NL</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>BR</td>\n<td>[   0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0]</td>\n</tr>\n<tr>\n<td>US</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码集：[0, 1, 0, 0, 0]</li>\n<li>编码稀疏： 2:1</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>标签编码（Label encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>为每个类别变量提供唯一的数字ID</li>\n<li>对于非线性基于树的算法很有用</li>\n<li>不增加维度</li>\n<li>随机化类别变量到数值变量的映射并重新训练， 平均以获得精度较小的凸凹</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘Queenstown’]\n<table>\n<thead>\n<tr>\n<th>城市  =&gt;</th>\n<th>city</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Cherbourg</td>\n<td>1</td>\n</tr>\n<tr>\n<td>Queenstown</td>\n<td>2</td>\n</tr>\n<tr>\n<td>Southhampton</td>\n<td>3</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [2]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>计数编码（Count encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>将类别变量替换为他们在训练数据中的计数</li>\n<li>适用于线性和非线性算法</li>\n<li>可以对异常值敏感</li>\n<li>可以加入对数转换（log transform）, 与计数一起工作的很好</li>\n<li>用‘1’替换看不见的数据</li>\n<li>可能会发生冲突：相同的编码，不同的变量</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘A6GHBD78’]\n<table>\n<thead>\n<tr>\n<th>teacher_id</th>\n<th>teacher_id</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n<tr>\n<td>A6GHBD78</td>\n<td>3</td>\n</tr>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n<tr>\n<td>FCKGWRHQ</td>\n<td>1</td>\n</tr>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n<tr>\n<td>A6GHBD78</td>\n<td>3</td>\n</tr>\n<tr>\n<td>A6GHBD78</td>\n<td>3</td>\n</tr>\n<tr>\n<td>DEADB33F</td>\n<td>4</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [3]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>标签计数编码（LabelCount encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>在训练数据中，对类别变量进行排名</li>\n<li>适用于线性和非线性算法</li>\n<li>对异常值不敏感</li>\n<li>不会对不同的变量赋予相同的编码</li>\n<li>两全其美</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘nl’]\n<table>\n<thead>\n<tr>\n<th>tld</th>\n<th>tld</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>nl</td>\n<td>3</td>\n</tr>\n<tr>\n<td>de</td>\n<td>2</td>\n</tr>\n<tr>\n<td>de</td>\n<td>2</td>\n</tr>\n<tr>\n<td>fr</td>\n<td>1</td>\n</tr>\n<tr>\n<td>fr</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [3]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Target encoding</p>\n<ul>\n<li>概念\n<ul>\n<li>根据目标比率对类别变量进行编码（二进制分类或回归）</li>\n<li>小心避免过度拟合（overfit）</li>\n<li>堆叠的形式：单变量模型，其输出平均目标</li>\n<li>以交叉验证方式进行</li>\n<li>添加平滑以避免将变量编码设置为0</li>\n<li>添加随机噪音以对抗过拟合</li>\n<li>什么时候用：线性和非线性的最佳编码</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>role</th>\n<th>y</th>\n<th>role</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>manager</td>\n<td>1</td>\n<td>0.5</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>1</td>\n<td>0.66</td>\n</tr>\n<tr>\n<td>scientist</td>\n<td>1</td>\n<td>1.</td>\n</tr>\n<tr>\n<td>manager</td>\n<td>0</td>\n<td>0.5</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>0</td>\n<td>0.66</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>1</td>\n<td>0.66</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>类别嵌入（Category Embedding）</p>\n<ul>\n<li>概念\n<ul>\n<li>使用神经网络从类别变量创建密集嵌入</li>\n<li>将函数逼近问题中的类别变量映射到欧几里德空间</li>\n<li>更快的模型训练</li>\n<li>减少内存开销</li>\n<li>可以提供比1-hot 编码更好的精准度</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>role</th>\n<th>role 3-D embedding</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>manager</td>\n<td>[0.05, 0.10, 0.96]</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>[0.72, 0.66, 0.17]</td>\n</tr>\n<tr>\n<td>scientist</td>\n<td>[0.75, 0.62, 0.15]</td>\n</tr>\n<tr>\n<td>manager</td>\n<td>[0.05, 0.10, 0.96]</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>[0.72, 0.66, 0.17]</td>\n</tr>\n<tr>\n<td>engineer</td>\n<td>[0.72, 0.66, 0.17]</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>NaN编码（NaN encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>为NaN值提供显式编码而不是忽略</li>\n<li>NaN值可以保存信息</li>\n<li>小心避免过度拟合</li>\n<li>仅在训练数据和测试数据中的Nan值是由相同的原因引起时才可以用，或者本地验证证明它持有信息</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>[‘NaN’]\n<table>\n<thead>\n<tr>\n<th>UA</th>\n<th>UA=mobile</th>\n<th>UA=tablet</th>\n<th>UA=NaN</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>mobile</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>tablet</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>mobile</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>NaN</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>mobile</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>编码： [0, 0, 1]</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>多项式编码（Polynomial encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>类别变量之间的编码交互</li>\n<li>没有交互的线性算法无法解决XOR问题</li>\n<li>多项式内核可以解决XOR问题</li>\n<li>爆炸式的特征空间： 使用FS，散列或者VW</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>A</th>\n<th>B</th>\n<th>y</th>\n<th>A=1*B=1</th>\n<th>A=0*B=1</th>\n<th>A=1*B=0</th>\n<th>A=0*B=0</th>\n<th>y</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>扩展编码（Expansion encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>从单个变量创建多个类别变量</li>\n<li>某些高基数功能（如用户代理）在其中包含更多信息：\n<ul>\n<li>is_mobile?</li>\n<li>is_latest_version?</li>\n<li>Operation_system</li>\n<li>Browser_build</li>\n<li>etc…</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>例子\n<ul>\n<li>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36<br>\n==&gt;\n<table>\n<thead>\n<tr>\n<th>UA1</th>\n<th>UA2</th>\n<th>UA3</th>\n<th>UA4</th>\n<th>UA5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Chrome</td>\n<td>53.0.2785.143</td>\n<td>Desktop</td>\n<td>Mac</td>\n<td>10_10_4</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>合并编码（Consolidation encoding）</p>\n<ul>\n<li>概念\n<ul>\n<li>将不同的类别变量映射到同一个变量</li>\n<li>拼写错误，略有不同的职位描述，全名 vs 缩写</li>\n<li>真实数据很乱，自由文本尤其如此</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>company_desc   =&gt;</th>\n<th>desc1</th>\n<th>company_desc2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Shell</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>shel</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>SHELL</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>Shell Gasonline</td>\n<td>Shell</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>BP</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>British Petr.</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>B&amp;P</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>BP Gas Station</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>bp</td>\n<td>BP</td>\n<td>Gas station</td>\n</tr>\n<tr>\n<td>Procter&amp;Gamble</td>\n<td>P&amp;G</td>\n<td>Manufacturer</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数值特征\"><a class=\"markdownIt-Anchor\" href=\"#数值特征\"></a> 数值特征</h4>\n<ul>\n<li>特点\n<ul>\n<li>可以更容易地输入算法</li>\n<li>可以构成浮点数，计数，数字</li>\n<li>更容易估算缺失的数据</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>四舍五入（Rounding）\n<ul>\n<li>概念\n<ul>\n<li>四舍五入数值变量</li>\n<li>有损压缩： 保留数据的最重要特征</li>\n<li>有时太精确只是噪音</li>\n<li>四舍五入的变量可以视为类别变量</li>\n<li>可以在四舍五入之前做对数变换</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>age</th>\n<th>age1</th>\n<th>age2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>23.6671</td>\n<td>23</td>\n<td>2</td>\n</tr>\n<tr>\n<td>23.8891</td>\n<td>23</td>\n<td>2</td>\n</tr>\n<tr>\n<td>22.1261</td>\n<td>22</td>\n<td>2</td>\n</tr>\n<tr>\n<td>19.5506</td>\n<td>19</td>\n<td>1</td>\n</tr>\n<tr>\n<td>18.2114</td>\n<td>18</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>分档（Binning）\n<ul>\n<li>概念\n<ul>\n<li>将数值变量放入bin（档）中并使用bin-ID进行编码</li>\n<li>分档可以务实设置，通过分位数，均匀的，或使用模型到最佳分档</li>\n<li>可以使得训练集所见范围以外的变量正常工作</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>risk_score</th>\n<th>rs[-inf, 33]</th>\n<th>rs[33,66]</th>\n<th>rs[66,inf]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>15</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>77</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>78</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>55</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n<tr>\n<td>42</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>缩放（Scaling）\n<ul>\n<li>概念\n<ul>\n<li>将数值变量扩展到特定范围</li>\n<li>Standard（Z）缩放</li>\n<li>MinMax 缩放</li>\n<li>Root 缩放</li>\n<li>Log 缩放</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>估算（Imputation）\n<ul>\n<li>概念\n<ul>\n<li>估算缺失的变量</li>\n<li>硬编码可与估算相结合</li>\n<li>平均：非常基本的</li>\n<li>中位数：对异常值鲁棒性比较高</li>\n<li>忽略： 只是推迟问题</li>\n<li>使用模型：可以暴露算法的偏差</li>\n</ul>\n</li>\n<li>例子\n<table>\n<thead>\n<tr>\n<th>wage</th>\n<th>hours</th>\n<th>gender</th>\n<th>y =&gt;</th>\n<th>wage</th>\n<th>hours</th>\n<th>gender_y</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1600</td>\n<td>40</td>\n<td>0</td>\n<td>1</td>\n<td>1600</td>\n<td>40</td>\n<td>0</td>\n</tr>\n<tr>\n<td>2200</td>\n<td>50</td>\n<td>1</td>\n<td>1</td>\n<td>2200</td>\n<td>50</td>\n<td>1</td>\n</tr>\n<tr>\n<td>1800</td>\n<td>36</td>\n<td>0</td>\n<td>0</td>\n<td>1800</td>\n<td>36</td>\n<td>0</td>\n</tr>\n<tr>\n<td>2100</td>\n<td>45</td>\n<td>1</td>\n<td>0</td>\n<td>2100</td>\n<td>45</td>\n<td>?</td>\n</tr>\n<tr>\n<td>2050</td>\n<td>60</td>\n<td>NaN</td>\n<td>0</td>\n<td>2050</td>\n<td>60</td>\n<td>?</td>\n</tr>\n<tr>\n<td>1650</td>\n<td>36</td>\n<td>0</td>\n<td>1</td>\n<td>1650</td>\n<td>36</td>\n<td>?</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>相互作用（Interactions）\n<ul>\n<li>概念\n<ul>\n<li>具体来说编码数值变量之间的相互作用</li>\n<li>尝试：减法，加法，乘法，除法</li>\n<li>使用：通过统 计测试选择特征，或训练模型特征重要性</li>\n<li>忽略：人的直觉; 奇怪的相互作用可以带来显著的改进</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>线性算法的非线性编码（No-linear encoding for linear algo’s）\n<ul>\n<li>概念\n<ul>\n<li>硬编码非线性以改进线性算法</li>\n<li>多项式内核</li>\n<li>叶编码（随机森林嵌入）</li>\n<li>遗传算法</li>\n<li>局部线性嵌入，光谱嵌入，t-SNE</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>行统计（Row statistics）\n<ul>\n<li>概念\n<ul>\n<li>创建一行数据的统计信息</li>\n<li>NaN的数量</li>\n<li>0的数量</li>\n<li>负数值的数量</li>\n<li>平均值，最大值，最小值，偏度 等</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"时间特征-temporal-variables\"><a class=\"markdownIt-Anchor\" href=\"#时间特征-temporal-variables\"></a> 时间特征 (Temporal variables)</h4>\n<ul>\n<li>特点\n<ul>\n<li>时间变量，如日期，需要更好的本地验证方案（如回测）</li>\n<li>容易在这里犯错误</li>\n<li>很多机会进行重大改进</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>投射到一个圆\n<ul>\n<li>将单个要素（如day_of_week）转换为圆上的两个坐标</li>\n<li>确保max和min之间的距离与min和min +1相同</li>\n<li>用于day_of_week，day_of_month，hour_of_day等</li>\n</ul>\n</li>\n<li>趋势线（Trendlines）\n<ul>\n<li>不是编码总支出，而是编码上周花费，上个月花费，去年花费。</li>\n<li>给算法的趋势：两个支出相同的客户可能会有截然不同的行为 - 一个客户可能开始花费更多，而另一个客户开始减少支出。</li>\n</ul>\n</li>\n<li>与重大事件的接近度（Closeness to major events）\n<ul>\n<li>硬编码类别特征，如：date_3_days_before_holidays = 1</li>\n<li>尝试：国庆节，重大体育赛事，周末，一个月的第一个星期六等</li>\n<li>这些因素可能对支出行为产生重大影响</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"空间特征spatial-variables\"><a class=\"markdownIt-Anchor\" href=\"#空间特征spatial-variables\"></a> 空间特征（Spatial Variables）</h4>\n<ul>\n<li>特点\n<ul>\n<li>空间变量是在空间编码的位置的变量</li>\n<li>例子包括：GPS坐标，城市，国家，地址</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>分类位置（Categorizing location）\n<ul>\n<li>克里金法（Kriging）</li>\n<li>K-means聚类</li>\n<li>原始纬度经度</li>\n<li>将城市转换为纬度经度</li>\n<li>将邮政编码添加到街道名称</li>\n</ul>\n</li>\n<li>与枢纽的接近度（Closeness to Hubs）\n<ul>\n<li>找到位置与主要枢纽之间的紧密程度</li>\n<li>小城镇继承了附近大城市的一些文化/背景</li>\n<li>电话位置可以映射到附近的企业和超市</li>\n</ul>\n</li>\n<li>空间欺诈行为（Spatial fraudulent behavior）\n<ul>\n<li>位置事件数据可以指示可疑行为</li>\n<li>不可能的旅行速度：不同国家的多个同步交易</li>\n<li>在不同的城镇消费，而不是在家或送货地址</li>\n<li>永远不要在同一地点消费</li>\n</ul>\n</li>\n<li>探索（Exploration）\n<ul>\n<li>数据探索可以发现数据健康问题，异常值，噪声，特征工程想法，特征清洗想法</li>\n<li>可以使用：Console, Notebook, Pandas</li>\n<li>尝试简单的统计数据：最小值，最大值</li>\n<li>将目标结合起来，以便在信息之间找到相关性</li>\n</ul>\n</li>\n<li>迭代/调试（Iteration / Debugging）\n<ul>\n<li>特征工程是一个迭代过程：使你的pipelines适合快速迭代</li>\n<li>使用子线性调试：输出有关过程的中间信息，进行伪log</li>\n<li>使用允许快速实验的工具</li>\n<li>失败的想法会多余成功的想法</li>\n</ul>\n</li>\n<li>标签工程（Label Engineering）\n<ul>\n<li>可以将标签/目标/因变量视为数据的一个特征，反之亦然</li>\n<li>对数变换：y  - &gt; log（y + 1）| exp（y_pred） -  1</li>\n<li>Square 变换</li>\n<li>Box-Cox变换</li>\n<li>创建分数，在回归中转换二进制目标</li>\n<li>训练回归器以预测测试集中不可用的特征</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"自然语言处理natural-language-processing\"><a class=\"markdownIt-Anchor\" href=\"#自然语言处理natural-language-processing\"></a> 自然语言处理（Natural Language Processing）</h4>\n<ul>\n<li>特点\n<ul>\n<li>可以用类别特征中相同的方法</li>\n<li>深度学习（自动特征工程）正在慢慢的吞噬这个领域，但是具有好的特征工程的浅学习仍然具有竞争力</li>\n<li>高稀疏性的数据将带来“维度诅咒”</li>\n<li>特征工程具有很多机会</li>\n</ul>\n</li>\n<li>方法\n<ul>\n<li>所有方法列表\n<ul>\n<li>转换成小写字母</li>\n<li>删除非字母数字</li>\n<li>修复</li>\n<li>编码标点符号</li>\n<li>符号化</li>\n<li>令牌克（Token-grams）</li>\n<li>skipgrams</li>\n<li>char-grams</li>\n<li>删除停用词</li>\n<li>删除罕见的单词</li>\n<li>非常常见的词</li>\n<li>拼写纠正</li>\n<li>砍字</li>\n<li>词干</li>\n<li>词形还原</li>\n<li>文档特征</li>\n<li>实体的插入和提取</li>\n<li>简化</li>\n<li>Word2Vec 和 GloVe / Doc2Vec</li>\n<li>字符串相似性</li>\n<li>阅读水平</li>\n<li>最近邻居</li>\n<li>TF*IDF</li>\n<li>BayesSVM，矢量化，LDA，LSA</li>\n</ul>\n</li>\n<li>清洗（Cleaning）\n<ul>\n<li>转换成小写字母：使标记独立于大写：“I work at NASA” -&gt; “i work at nasa”.</li>\n<li>转换成Unidecode：将字符转换为ascii-对应物：</li>\n<li>删除非字母数字：删除不在[a-z] [A-Z] [0-9]中的任何内容来清理文本，“Breaking! Amsterdam (2009)” -&gt; “Breaking Amsterdam 2009”</li>\n<li>修复：修复编码问题或修剪intertoken空格。 “C a s a C a f＆eacute;” - &gt;“CasaCafé”</li>\n</ul>\n</li>\n<li>符号化（Tokenizing）\n<ul>\n<li>编码标点符号：硬编码“！”和“？”作为标记。</li>\n<li>符号化（Tokenize）：划分句子标记成单词记号</li>\n<li>N-Grams：将连续的符号编码为符号,  “I like the Beatles” -&gt; [“I like”, “like the”, “the Beatles”]</li>\n<li>Skip-grams: 编码连续的符号，但跳过一些,  “I like the Beatles” -&gt; [“I the”, “like Beatles”]</li>\n<li>Char-grams: 与N-gram相同，但字符级别, “Beatles” - &gt; [“Bea”, “eat”, “atl”, “tle”, “les”]</li>\n<li>Affixes：与char-gram相同，但是仅限于前缀与后缀</li>\n</ul>\n</li>\n<li>删除（Removing）\n<ul>\n<li>停用词：删除停用词列表中出现的单词/标记</li>\n<li>稀有单词：删除仅在训练集中出现几次的单词</li>\n<li>常用词：删除可能不在停用词列表中的极其常见的词</li>\n</ul>\n</li>\n<li>根（Roots）\n<ul>\n<li>拼写纠正：将字符更改为正确的拼写</li>\n<li>切（chop）： 仅取一个单词的前n（8）个字符</li>\n<li>词干：将词/标记减少到其根， “cars” -&gt; “car”</li>\n<li>Lemmatize：找到语义根， “never be late” -&gt; “never are late”</li>\n</ul>\n</li>\n<li>丰富（Enrich）\n<ul>\n<li>文档特征：计算空格数量，tab数量，换行数量，字符数量，以及令牌数量等</li>\n<li>实体插入：向文本中插入更多的通用的规范， “Microsoft releases Windows” -&gt; “Microsoft (company) releases Windows (application)”</li>\n<li>解析树：将句子解析为逻辑形式，“Alice hits Bill” -&gt; Alice/Noun_subject hits/Verb Bill/Noun_object.</li>\n<li>阅读级别：计算文档的阅读级别</li>\n</ul>\n</li>\n<li>相似性（Similarities）\n<ul>\n<li>令牌相似性：计算出现在两个文本中的令牌数</li>\n<li>压缩距离：查看是否可以使用其他文本更好地压缩一个文本</li>\n<li>Levenshtein / Hamming / Jaccard 距离：通过查看在另一个字符串中转换一个字符串所需的操作数来检查两个字符串之间的相似性</li>\n<li>Word2Vec / Glove：检查两个平均向量之间的余弦相似度</li>\n</ul>\n</li>\n<li>TF-IDF\n<ul>\n<li>术语频率：减少对长文档的偏差</li>\n<li>反向文档频率：减少对常见令牌的偏差</li>\n<li>TF-IDF：用于标识文档中最重要的标记，删除不重要的标记，或作为降维的预处理步骤</li>\n</ul>\n</li>\n<li>降维\n<ul>\n<li>PCA：将文本缩小为50或100维向量</li>\n<li>SVD：将文本缩小为50或100维向量</li>\n<li>LDA：TF-IDF，然后是SVD</li>\n<li>LSA：创建主题向量</li>\n</ul>\n</li>\n<li>外部模型\n<ul>\n<li>情绪分析器：为任何文本获取负面或正面情绪的向量</li>\n<li>主题模型：使用另一个数据集为新数据集创建主题向量</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"深度学习神经网络\"><a class=\"markdownIt-Anchor\" href=\"#深度学习神经网络\"></a> 深度学习/神经网络</h4>\n<ul>\n<li>神经网络声称是端到端的自动特征工程。所以特征工程没用了么？并不是这样的。特征工程将重点转移到架构工程。</li>\n<li>尽管承诺：计算机视觉使用的特征， 例如：\n<ul>\n<li>HOG</li>\n<li>SIFT</li>\n<li>whitening</li>\n<li>perturbation</li>\n<li>image pyramids</li>\n<li>rotation</li>\n<li>z-scaling</li>\n<li>log-scaling</li>\n<li>frame- grams</li>\n<li>external semantic data</li>\n<li>…</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"leakage-golden-features\"><a class=\"markdownIt-Anchor\" href=\"#leakage-golden-features\"></a> Leakage / Golden Features</h4>\n<ul>\n<li>特征工程可以帮助利用泄露</li>\n<li>逆向工程\n<ul>\n<li>使用rainbow表反转 MD5 Hash</li>\n<li>将 TF-IDF反转回术语频率</li>\n<li>编码样本数据集的顺序</li>\n<li>编码文件创建日期</li>\n</ul>\n</li>\n<li>规则挖掘\n<ul>\n<li>查找简单的规则（并对其进行编码）以帮助您的模型</li>\n</ul>\n</li>\n</ul>\n<!-- $$\nf(n) = \\begin{cases}\n \\frac{n}{2},\n & \\text{if } n\\text{ is even}\n \\\\ 3n+1, & \\text{if } n\\text{ is odd}\n \\end{cases}\n$$ -->\n<h3 id=\"参考资料\"><a class=\"markdownIt-Anchor\" href=\"#参考资料\"></a> 参考资料</h3>\n<p><a href=\"https://www.slideshare.net/HJvanVeen/feature-engineering-72376750\" target=\"_blank\" rel=\"noopener\">Tips &amp; Tricks for Feature Engineering / Applied Machine Learning</a><br>\n[]</p>\n"},{"title":"机器学习优化方法","catalog":true,"toc_nav_num":true,"mathjax":true,"date":"2019-07-30T10:30:24.000Z","subtitle":null,"header-img":"/img/article_header/article_header.png","catagories":["机器学习"],"_content":"\n> 机器学习算法 = 模型表征 + 模型评估 + 优化算法\n>\n> 无论何种类型的机器学习，最后都归结为求解最优化问题\n>\n> 求一个目标函数的极值=> 最优化问题\n\n\n### 数学模型\n#### 监督学习\n* 找到一个最佳的映射函数f(x)，使得对训练样本的损失函数最小化（最小化经验风险或结构风险)\n  $$\n  min_{W}\\frac{1}{N}\\sum_{i=1}^{N}L(W,x_{i},y_{i}) + \\lambda||W||_{2}^2\n  $$\n  N为训练样本数，L是对单个样本的损失函数，w是要求解的模型参数，是映射函数的参数 $x_{i}$为样本的特征向量, $y_{i}$ 为样本的标签值\n* 一个最优的概率密度函数p(x)，使得对训练样本的对数似然函数极大化（最大似然估计）\n  $$\n  max\\sum_{i=1}^l\\lnp(x_{i};\\theta)\n  $$\n  $\\theta$ 是要求解的模型参数，是概率密度函数的参数。\n#### 非监督学习\n* 以聚类算法为例，算法要是的每个类的样本离类中心的距离之和最小化\n  $$\n    min_{S}\\sum_{i=1}^k\\sum_{x \\in S_{i}}||x-\\mu_{i}||^2\n  $$\n  k为类型数，x为样本向量， $\\mu_{i}$ 为类中心向量， $S_{i}$ 为第 $i$ 个类的样本集合\n* 强化学习， 要找到一个最优的策略，即状态s到动作a的映射函数（确定性策略，对于非确定性策略，是执行每个动作的概率）\n  $$\n    a=\\pi(s)\n  $$\n  任意给定一个状态，执行这个策略函数所确定的动作a之后，得到的累计回报最大化:\n  $$\n    max_{\\pi}V_{\\pi}(s)\n  $$\n  使用的是状态价值函数\n### 优化算法分类\n\n\n\n\n\n\n### 参考资料\n* [机器学习中的最优化算法总结](https://zhuanlan.zhihu.com/p/42689565)\n* [你想知道的特征工程，机器学习优化方法都在这了！收藏！](https://juejin.im/post/*5d3bb3c5e51d455d6d53591d#heading-7)\n* [机器学习中的优化方法](https://zhuanlan.zhihu.com/p/36196698)\n* [理解机器学习中常用优化方法](http://oath2yangmen.online/2018/01/29/%E7%90%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/)","source":"_posts/2019-07-30-机器学习优化方法.md","raw":"---\ntitle: \"机器学习优化方法\"\ncatalog: true\ntoc_nav_num: true\nmathjax: true\ndate: 2019-07-30 18:30:24\nsubtitle:\nheader-img: \"/img/article_header/article_header.png\"\ntags:\n- 优化方法\ncatagories:\n- 机器学习\n\n---\n\n> 机器学习算法 = 模型表征 + 模型评估 + 优化算法\n>\n> 无论何种类型的机器学习，最后都归结为求解最优化问题\n>\n> 求一个目标函数的极值=> 最优化问题\n\n\n### 数学模型\n#### 监督学习\n* 找到一个最佳的映射函数f(x)，使得对训练样本的损失函数最小化（最小化经验风险或结构风险)\n  $$\n  min_{W}\\frac{1}{N}\\sum_{i=1}^{N}L(W,x_{i},y_{i}) + \\lambda||W||_{2}^2\n  $$\n  N为训练样本数，L是对单个样本的损失函数，w是要求解的模型参数，是映射函数的参数 $x_{i}$为样本的特征向量, $y_{i}$ 为样本的标签值\n* 一个最优的概率密度函数p(x)，使得对训练样本的对数似然函数极大化（最大似然估计）\n  $$\n  max\\sum_{i=1}^l\\lnp(x_{i};\\theta)\n  $$\n  $\\theta$ 是要求解的模型参数，是概率密度函数的参数。\n#### 非监督学习\n* 以聚类算法为例，算法要是的每个类的样本离类中心的距离之和最小化\n  $$\n    min_{S}\\sum_{i=1}^k\\sum_{x \\in S_{i}}||x-\\mu_{i}||^2\n  $$\n  k为类型数，x为样本向量， $\\mu_{i}$ 为类中心向量， $S_{i}$ 为第 $i$ 个类的样本集合\n* 强化学习， 要找到一个最优的策略，即状态s到动作a的映射函数（确定性策略，对于非确定性策略，是执行每个动作的概率）\n  $$\n    a=\\pi(s)\n  $$\n  任意给定一个状态，执行这个策略函数所确定的动作a之后，得到的累计回报最大化:\n  $$\n    max_{\\pi}V_{\\pi}(s)\n  $$\n  使用的是状态价值函数\n### 优化算法分类\n\n\n\n\n\n\n### 参考资料\n* [机器学习中的最优化算法总结](https://zhuanlan.zhihu.com/p/42689565)\n* [你想知道的特征工程，机器学习优化方法都在这了！收藏！](https://juejin.im/post/*5d3bb3c5e51d455d6d53591d#heading-7)\n* [机器学习中的优化方法](https://zhuanlan.zhihu.com/p/36196698)\n* [理解机器学习中常用优化方法](http://oath2yangmen.online/2018/01/29/%E7%90%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/)","slug":"2019-07-30-机器学习优化方法","published":1,"updated":"2019-08-01T10:08:38.473Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjysio1q50003chovt0yn9pwv","content":"<blockquote>\n<p>机器学习算法 = 模型表征 + 模型评估 + 优化算法</p>\n<p>无论何种类型的机器学习，最后都归结为求解最优化问题</p>\n<p>求一个目标函数的极值=&gt; 最优化问题</p>\n</blockquote>\n<h3 id=\"数学模型\"><a class=\"markdownIt-Anchor\" href=\"#数学模型\"></a> 数学模型</h3>\n<h4 id=\"监督学习\"><a class=\"markdownIt-Anchor\" href=\"#监督学习\"></a> 监督学习</h4>\n<ul>\n<li>找到一个最佳的映射函数f(x)，使得对训练样本的损失函数最小化（最小化经验风险或结构风险)<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>W</mi></mrow></msub><mfrac><mrow><mn>1</mn></mrow><mrow><mi>N</mi></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi></mrow></msubsup><mi>L</mi><mo>(</mo><mi>W</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mrow><mi>i</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>i</mi></mrow></msub><mo>)</mo><mo>+</mo><mi>λ</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>W</mi><mi mathvariant=\"normal\">∣</mi><msubsup><mi mathvariant=\"normal\">∣</mi><mrow><mn>2</mn></mrow><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">min_{W}\\frac{1}{N}\\sum_{i=1}^{N}L(W,x_{i},y_{i}) + \\lambda||W||_{2}^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.8283360000000002em;\"></span><span class=\"strut bottom\" style=\"height:3.106005em;vertical-align:-1.277669em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">m</span><span class=\"mord mathit\">i</span><span class=\"mord\"><span class=\"mord mathit\">n</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-0.22999999999999998em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1776689999999999em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∑</span></span></span><span style=\"top:-1.2500050000000003em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord scriptstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">W</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.03588em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mclose\">)</span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"vlist\"><span style=\"top:0.247em;margin-left:0em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathrm\">2</span></span></span></span><span style=\"top:-0.4129999999999999em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathrm\">2</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span></span></p>\nN为训练样本数，L是对单个样本的损失函数，w是要求解的模型参数，是映射函数的参数 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">x_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>为样本的特征向量, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">y_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.03588em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span> 为样本的标签值</li>\n<li>一个最优的概率密度函数p(x)，使得对训练样本的对数似然函数极大化（最大似然估计）max\\sum_{i=1}^l\\lnp(x_{i};\\theta)\n\n<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span> 是要求解的模型参数，是概率密度函数的参数。</li>\n</ul>\n<h4 id=\"非监督学习\"><a class=\"markdownIt-Anchor\" href=\"#非监督学习\"></a> 非监督学习</h4>\n<ul>\n<li>以聚类算法为例，算法要是的每个类的样本离类中心的距离之和最小化<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>S</mi></mrow></msub><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><msub><mi>S</mi><mrow><mi>i</mi></mrow></msub></mrow></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mrow><mi>i</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">  min_{S}\\sum_{i=1}^k\\sum_{x \\in S_{i}}||x-\\mu_{i}||^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.8361130000000003em;\"></span><span class=\"strut bottom\" style=\"height:3.235449em;vertical-align:-1.399336em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">m</span><span class=\"mord mathit\">i</span><span class=\"mord\"><span class=\"mord mathit\">n</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1776689999999999em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∑</span></span></span><span style=\"top:-1.2500050000000003em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1943359999999998em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">x</span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.05764em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∑</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathit\">x</span><span class=\"mbin\">−</span><span class=\"mord\"><span class=\"mord mathit\">μ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"vlist\"><span style=\"top:-0.413em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathrm\">2</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span></span></p>\nk为类型数，x为样本向量， <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>μ</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mu_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">μ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span> 为类中心向量， <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>S</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">S_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.05764em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span> 为第 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">i</span></span></span></span> 个类的样本集合</li>\n<li>强化学习， 要找到一个最优的策略，即状态s到动作a的映射函数（确定性策略，对于非确定性策略，是执行每个动作的概率）<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>=</mo><mi>π</mi><mo>(</mo><mi>s</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">  a=\\pi(s)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">a</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord mathit\">s</span><span class=\"mclose\">)</span></span></span></span></span></p>\n任意给定一个状态，执行这个策略函数所确定的动作a之后，得到的累计回报最大化:<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>a</mi><msub><mi>x</mi><mrow><mi>π</mi></mrow></msub><msub><mi>V</mi><mrow><mi>π</mi></mrow></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">  max_{\\pi}V_{\\pi}(s)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.22222em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">s</span><span class=\"mclose\">)</span></span></span></span></span></p>\n使用的是状态价值函数</li>\n</ul>\n<h3 id=\"优化算法分类\"><a class=\"markdownIt-Anchor\" href=\"#优化算法分类\"></a> 优化算法分类</h3>\n<h3 id=\"参考资料\"><a class=\"markdownIt-Anchor\" href=\"#参考资料\"></a> 参考资料</h3>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/42689565\" target=\"_blank\" rel=\"noopener\">机器学习中的最优化算法总结</a></li>\n<li><a href=\"https://juejin.im/post/*5d3bb3c5e51d455d6d53591d#heading-7\" target=\"_blank\" rel=\"noopener\">你想知道的特征工程，机器学习优化方法都在这了！收藏！</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/36196698\" target=\"_blank\" rel=\"noopener\">机器学习中的优化方法</a></li>\n<li><a href=\"http://oath2yangmen.online/2018/01/29/%E7%90%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">理解机器学习中常用优化方法</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>机器学习算法 = 模型表征 + 模型评估 + 优化算法</p>\n<p>无论何种类型的机器学习，最后都归结为求解最优化问题</p>\n<p>求一个目标函数的极值=&gt; 最优化问题</p>\n</blockquote>\n<h3 id=\"数学模型\"><a class=\"markdownIt-Anchor\" href=\"#数学模型\"></a> 数学模型</h3>\n<h4 id=\"监督学习\"><a class=\"markdownIt-Anchor\" href=\"#监督学习\"></a> 监督学习</h4>\n<ul>\n<li>找到一个最佳的映射函数f(x)，使得对训练样本的损失函数最小化（最小化经验风险或结构风险)<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>W</mi></mrow></msub><mfrac><mrow><mn>1</mn></mrow><mrow><mi>N</mi></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi></mrow></msubsup><mi>L</mi><mo>(</mo><mi>W</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mrow><mi>i</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>i</mi></mrow></msub><mo>)</mo><mo>+</mo><mi>λ</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>W</mi><mi mathvariant=\"normal\">∣</mi><msubsup><mi mathvariant=\"normal\">∣</mi><mrow><mn>2</mn></mrow><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">min_{W}\\frac{1}{N}\\sum_{i=1}^{N}L(W,x_{i},y_{i}) + \\lambda||W||_{2}^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.8283360000000002em;\"></span><span class=\"strut bottom\" style=\"height:3.106005em;vertical-align:-1.277669em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">m</span><span class=\"mord mathit\">i</span><span class=\"mord\"><span class=\"mord mathit\">n</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-0.22999999999999998em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1776689999999999em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∑</span></span></span><span style=\"top:-1.2500050000000003em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord scriptstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">W</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.03588em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mclose\">)</span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"vlist\"><span style=\"top:0.247em;margin-left:0em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathrm\">2</span></span></span></span><span style=\"top:-0.4129999999999999em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathrm\">2</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span></span></p>\nN为训练样本数，L是对单个样本的损失函数，w是要求解的模型参数，是映射函数的参数 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">x_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>为样本的特征向量, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">y_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.03588em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span> 为样本的标签值</li>\n<li>一个最优的概率密度函数p(x)，使得对训练样本的对数似然函数极大化（最大似然估计）max\\sum_{i=1}^l\\lnp(x_{i};\\theta)\n\n<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span> 是要求解的模型参数，是概率密度函数的参数。</li>\n</ul>\n<h4 id=\"非监督学习\"><a class=\"markdownIt-Anchor\" href=\"#非监督学习\"></a> 非监督学习</h4>\n<ul>\n<li>以聚类算法为例，算法要是的每个类的样本离类中心的距离之和最小化<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>S</mi></mrow></msub><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><msub><mi>S</mi><mrow><mi>i</mi></mrow></msub></mrow></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mrow><mi>i</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">  min_{S}\\sum_{i=1}^k\\sum_{x \\in S_{i}}||x-\\mu_{i}||^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.8361130000000003em;\"></span><span class=\"strut bottom\" style=\"height:3.235449em;vertical-align:-1.399336em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">m</span><span class=\"mord mathit\">i</span><span class=\"mord\"><span class=\"mord mathit\">n</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1776689999999999em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∑</span></span></span><span style=\"top:-1.2500050000000003em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1943359999999998em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">x</span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.05764em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∑</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathit\">x</span><span class=\"mbin\">−</span><span class=\"mord\"><span class=\"mord mathit\">μ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"vlist\"><span style=\"top:-0.413em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathrm\">2</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span></span></p>\nk为类型数，x为样本向量， <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>μ</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mu_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">μ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span> 为类中心向量， <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>S</mi><mrow><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">S_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.05764em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span> 为第 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">i</span></span></span></span> 个类的样本集合</li>\n<li>强化学习， 要找到一个最优的策略，即状态s到动作a的映射函数（确定性策略，对于非确定性策略，是执行每个动作的概率）<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>=</mo><mi>π</mi><mo>(</mo><mi>s</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">  a=\\pi(s)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">a</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord mathit\">s</span><span class=\"mclose\">)</span></span></span></span></span></p>\n任意给定一个状态，执行这个策略函数所确定的动作a之后，得到的累计回报最大化:<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>a</mi><msub><mi>x</mi><mrow><mi>π</mi></mrow></msub><msub><mi>V</mi><mrow><mi>π</mi></mrow></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">  max_{\\pi}V_{\\pi}(s)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.22222em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">s</span><span class=\"mclose\">)</span></span></span></span></span></p>\n使用的是状态价值函数</li>\n</ul>\n<h3 id=\"优化算法分类\"><a class=\"markdownIt-Anchor\" href=\"#优化算法分类\"></a> 优化算法分类</h3>\n<h3 id=\"参考资料\"><a class=\"markdownIt-Anchor\" href=\"#参考资料\"></a> 参考资料</h3>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/42689565\" target=\"_blank\" rel=\"noopener\">机器学习中的最优化算法总结</a></li>\n<li><a href=\"https://juejin.im/post/*5d3bb3c5e51d455d6d53591d#heading-7\" target=\"_blank\" rel=\"noopener\">你想知道的特征工程，机器学习优化方法都在这了！收藏！</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/36196698\" target=\"_blank\" rel=\"noopener\">机器学习中的优化方法</a></li>\n<li><a href=\"http://oath2yangmen.online/2018/01/29/%E7%90%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">理解机器学习中常用优化方法</a></li>\n</ul>\n"},{"title":"2019年8月-12月学习计划","catalog":true,"toc_nav_num":true,"date":"2019-07-31T10:30:24.000Z","subtitle":null,"header-img":"/img/article_header/article_header.png","catagories":["学习计划"],"_content":"\n> 学无止境，学海无涯\n>\n> 专注深入的学习技术\n\n### 机器学习基础\n#### 机器学习概念、应用与前沿\n* 内容\n  机器学习技术和应用场景的介绍。常见算法，主流的应用构建方法。主流机器学习框架介绍，针对机器学习场景能够更好的应用相关工具进行分析与处理。\n* 项目\n  - 鸢尾花分类实战\n  - 分类预测实战\n  - 回归预测实战\n\n#### 数学基础-数学概念\n* 内容\n  机器学习中用到的数学基础由浅入深进行详细的梳理与讲解。主要涉及矩阵、导数、概率相关内容。\n  概率论，矩阵和凸优化的介绍，相应算法设计和原理；凸优化理论，流优化手段SGD等优化方法。\n* 项目\n  - 手写识别实战\n  - 文本降维实战\n#### 特征工程 & 可视化\n* 内容\n  Python数据预处理库，原始数据特征构建。特征选择，构建新特征，缺失值填充等特征工程方法学习。\n* 项目\n  - Scikit-learn特征工程，网格搜索，超参数调优。\n  - 泰坦尼克求生预测\n\n### 机器学习算法学习\n#### 决策树与随机森林算法\n* 内容\n  决策树算法的原理，度量指标和算法变种。掌握和了解GBDT，AdaBoost，随机森林等集成学习模型的原理和集成学习算法。\n* 项目\n  - 鸢尾花分类实战\n  - 金融反欺诈预测\n\n#### 分类算法\n* 内容\n  - 了解和掌握KNN、SVM及朴素贝叶斯算法原理。\n  - 熟悉集成学习对于分类算法的优化过程。掌握数据降维方法应用。\n  - 熟悉分类算法调参关键参数\n  - 掌握不同分类算法的过拟合、欠拟合情景与调优\n  - 掌握集成学习调优\n  - 了解不同算法的共性与个性\n* 项目\n  - 手写图形数据降维与分类\n  - 文本向量化实战\n  - 文本分类实战\n\n#### 回归算法\n* 内容\n  - 主流回归模型，线性回归，逻辑回归LR、Softmax及其变种和扩展算法。\n  - 梯度下降，牛顿法等优化方法，逻辑回归最优化问题的求解，正则化方法。\n* 项目\n  - 波士顿房价预测\n  - 股票预测回归实战\n\n### 大数据框架应用\n#### 聚类算法\n* 内容\n  无监督学习模型，了解主流的聚类算法。了解不同相似度计算算法。深入了解不同的数据降维方法。掌握文本降维方法(LDA)。\n  - 掌握 Kmeans 以及其衍生算法\n  - 掌握 modelbased 聚类方法\n  - 掌握无监督降维方法：PCA、ICA、字典学习\n  - 掌握监督降维方法：LDA\n  - 掌握文本降维方法：LDA\n  - 深入理解聚类算法与分类算法的区别\n  - 理解聚类算法的优缺点\n* 项目\n  - 新闻分类实战\n  - 文本降维实战\n\n#### 深度学习框架 TensorFlow\n* 内容\n  通过掌握 Tensorflow 基本概念，计算模型 和原理，能够通过 Tensorflow 进行深度学习和模型构建与训练。学习掌握训练过程优化方法与问题优化。\n  - 学习变量作用域与变量命名\n  - 搭建多层神经网络并完成优化\n  - 正则化优化神经网络\n  - 梯度问题与解决方法\n* 项目\n  - 图片分类实战\n  - 贷款欺诈预测\n\n#### 大数据\n* 内容\n  大数据主流分析框架为例， Spark 内核架构，计算模型和原理，了解分布式机器学习原理，能够处理和解决大规模数据分析预处理和模型训练。\n  - 了解和掌握 Spark 框架上的机器学习库 MLlib 的算法原理，核心数据抽象，以及应 用 MLlib。\n* 项目\n  - 电影推荐案例","source":"_posts/2019-07-31-2019-下半年学习计划.md","raw":"---\ntitle: \"2019年8月-12月学习计划\"\ncatalog: true\ntoc_nav_num: true\n# mathjax: true\ndate: 2019-07-31 18:30:24\nsubtitle:\nheader-img: \"/img/article_header/article_header.png\"\ntags:\n- 学习计划\ncatagories:\n- 学习计划\n\n---\n\n> 学无止境，学海无涯\n>\n> 专注深入的学习技术\n\n### 机器学习基础\n#### 机器学习概念、应用与前沿\n* 内容\n  机器学习技术和应用场景的介绍。常见算法，主流的应用构建方法。主流机器学习框架介绍，针对机器学习场景能够更好的应用相关工具进行分析与处理。\n* 项目\n  - 鸢尾花分类实战\n  - 分类预测实战\n  - 回归预测实战\n\n#### 数学基础-数学概念\n* 内容\n  机器学习中用到的数学基础由浅入深进行详细的梳理与讲解。主要涉及矩阵、导数、概率相关内容。\n  概率论，矩阵和凸优化的介绍，相应算法设计和原理；凸优化理论，流优化手段SGD等优化方法。\n* 项目\n  - 手写识别实战\n  - 文本降维实战\n#### 特征工程 & 可视化\n* 内容\n  Python数据预处理库，原始数据特征构建。特征选择，构建新特征，缺失值填充等特征工程方法学习。\n* 项目\n  - Scikit-learn特征工程，网格搜索，超参数调优。\n  - 泰坦尼克求生预测\n\n### 机器学习算法学习\n#### 决策树与随机森林算法\n* 内容\n  决策树算法的原理，度量指标和算法变种。掌握和了解GBDT，AdaBoost，随机森林等集成学习模型的原理和集成学习算法。\n* 项目\n  - 鸢尾花分类实战\n  - 金融反欺诈预测\n\n#### 分类算法\n* 内容\n  - 了解和掌握KNN、SVM及朴素贝叶斯算法原理。\n  - 熟悉集成学习对于分类算法的优化过程。掌握数据降维方法应用。\n  - 熟悉分类算法调参关键参数\n  - 掌握不同分类算法的过拟合、欠拟合情景与调优\n  - 掌握集成学习调优\n  - 了解不同算法的共性与个性\n* 项目\n  - 手写图形数据降维与分类\n  - 文本向量化实战\n  - 文本分类实战\n\n#### 回归算法\n* 内容\n  - 主流回归模型，线性回归，逻辑回归LR、Softmax及其变种和扩展算法。\n  - 梯度下降，牛顿法等优化方法，逻辑回归最优化问题的求解，正则化方法。\n* 项目\n  - 波士顿房价预测\n  - 股票预测回归实战\n\n### 大数据框架应用\n#### 聚类算法\n* 内容\n  无监督学习模型，了解主流的聚类算法。了解不同相似度计算算法。深入了解不同的数据降维方法。掌握文本降维方法(LDA)。\n  - 掌握 Kmeans 以及其衍生算法\n  - 掌握 modelbased 聚类方法\n  - 掌握无监督降维方法：PCA、ICA、字典学习\n  - 掌握监督降维方法：LDA\n  - 掌握文本降维方法：LDA\n  - 深入理解聚类算法与分类算法的区别\n  - 理解聚类算法的优缺点\n* 项目\n  - 新闻分类实战\n  - 文本降维实战\n\n#### 深度学习框架 TensorFlow\n* 内容\n  通过掌握 Tensorflow 基本概念，计算模型 和原理，能够通过 Tensorflow 进行深度学习和模型构建与训练。学习掌握训练过程优化方法与问题优化。\n  - 学习变量作用域与变量命名\n  - 搭建多层神经网络并完成优化\n  - 正则化优化神经网络\n  - 梯度问题与解决方法\n* 项目\n  - 图片分类实战\n  - 贷款欺诈预测\n\n#### 大数据\n* 内容\n  大数据主流分析框架为例， Spark 内核架构，计算模型和原理，了解分布式机器学习原理，能够处理和解决大规模数据分析预处理和模型训练。\n  - 了解和掌握 Spark 框架上的机器学习库 MLlib 的算法原理，核心数据抽象，以及应 用 MLlib。\n* 项目\n  - 电影推荐案例","slug":"2019-07-31-2019-下半年学习计划","published":1,"updated":"2019-07-31T07:38:47.028Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjysio1q90006chovjq4euvgz","content":"<blockquote>\n<p>学无止境，学海无涯</p>\n<p>专注深入的学习技术</p>\n</blockquote>\n<h3 id=\"机器学习基础\"><a class=\"markdownIt-Anchor\" href=\"#机器学习基础\"></a> 机器学习基础</h3>\n<h4 id=\"机器学习概念-应用与前沿\"><a class=\"markdownIt-Anchor\" href=\"#机器学习概念-应用与前沿\"></a> 机器学习概念、应用与前沿</h4>\n<ul>\n<li>内容<br>\n机器学习技术和应用场景的介绍。常见算法，主流的应用构建方法。主流机器学习框架介绍，针对机器学习场景能够更好的应用相关工具进行分析与处理。</li>\n<li>项目\n<ul>\n<li>鸢尾花分类实战</li>\n<li>分类预测实战</li>\n<li>回归预测实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数学基础-数学概念\"><a class=\"markdownIt-Anchor\" href=\"#数学基础-数学概念\"></a> 数学基础-数学概念</h4>\n<ul>\n<li>内容<br>\n机器学习中用到的数学基础由浅入深进行详细的梳理与讲解。主要涉及矩阵、导数、概率相关内容。<br>\n概率论，矩阵和凸优化的介绍，相应算法设计和原理；凸优化理论，流优化手段SGD等优化方法。</li>\n<li>项目\n<ul>\n<li>手写识别实战</li>\n<li>文本降维实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"特征工程-amp-可视化\"><a class=\"markdownIt-Anchor\" href=\"#特征工程-可视化\"></a> 特征工程 &amp; 可视化</h4>\n<ul>\n<li>内容<br>\nPython数据预处理库，原始数据特征构建。特征选择，构建新特征，缺失值填充等特征工程方法学习。</li>\n<li>项目\n<ul>\n<li>Scikit-learn特征工程，网格搜索，超参数调优。</li>\n<li>泰坦尼克求生预测</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"机器学习算法学习\"><a class=\"markdownIt-Anchor\" href=\"#机器学习算法学习\"></a> 机器学习算法学习</h3>\n<h4 id=\"决策树与随机森林算法\"><a class=\"markdownIt-Anchor\" href=\"#决策树与随机森林算法\"></a> 决策树与随机森林算法</h4>\n<ul>\n<li>内容<br>\n决策树算法的原理，度量指标和算法变种。掌握和了解GBDT，AdaBoost，随机森林等集成学习模型的原理和集成学习算法。</li>\n<li>项目\n<ul>\n<li>鸢尾花分类实战</li>\n<li>金融反欺诈预测</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"分类算法\"><a class=\"markdownIt-Anchor\" href=\"#分类算法\"></a> 分类算法</h4>\n<ul>\n<li>内容\n<ul>\n<li>了解和掌握KNN、SVM及朴素贝叶斯算法原理。</li>\n<li>熟悉集成学习对于分类算法的优化过程。掌握数据降维方法应用。</li>\n<li>熟悉分类算法调参关键参数</li>\n<li>掌握不同分类算法的过拟合、欠拟合情景与调优</li>\n<li>掌握集成学习调优</li>\n<li>了解不同算法的共性与个性</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>手写图形数据降维与分类</li>\n<li>文本向量化实战</li>\n<li>文本分类实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"回归算法\"><a class=\"markdownIt-Anchor\" href=\"#回归算法\"></a> 回归算法</h4>\n<ul>\n<li>内容\n<ul>\n<li>主流回归模型，线性回归，逻辑回归LR、Softmax及其变种和扩展算法。</li>\n<li>梯度下降，牛顿法等优化方法，逻辑回归最优化问题的求解，正则化方法。</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>波士顿房价预测</li>\n<li>股票预测回归实战</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"大数据框架应用\"><a class=\"markdownIt-Anchor\" href=\"#大数据框架应用\"></a> 大数据框架应用</h3>\n<h4 id=\"聚类算法\"><a class=\"markdownIt-Anchor\" href=\"#聚类算法\"></a> 聚类算法</h4>\n<ul>\n<li>内容<br>\n无监督学习模型，了解主流的聚类算法。了解不同相似度计算算法。深入了解不同的数据降维方法。掌握文本降维方法(LDA)。\n<ul>\n<li>掌握 Kmeans 以及其衍生算法</li>\n<li>掌握 modelbased 聚类方法</li>\n<li>掌握无监督降维方法：PCA、ICA、字典学习</li>\n<li>掌握监督降维方法：LDA</li>\n<li>掌握文本降维方法：LDA</li>\n<li>深入理解聚类算法与分类算法的区别</li>\n<li>理解聚类算法的优缺点</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>新闻分类实战</li>\n<li>文本降维实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"深度学习框架-tensorflow\"><a class=\"markdownIt-Anchor\" href=\"#深度学习框架-tensorflow\"></a> 深度学习框架 TensorFlow</h4>\n<ul>\n<li>内容<br>\n通过掌握 Tensorflow 基本概念，计算模型 和原理，能够通过 Tensorflow 进行深度学习和模型构建与训练。学习掌握训练过程优化方法与问题优化。\n<ul>\n<li>学习变量作用域与变量命名</li>\n<li>搭建多层神经网络并完成优化</li>\n<li>正则化优化神经网络</li>\n<li>梯度问题与解决方法</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>图片分类实战</li>\n<li>贷款欺诈预测</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"大数据\"><a class=\"markdownIt-Anchor\" href=\"#大数据\"></a> 大数据</h4>\n<ul>\n<li>内容<br>\n大数据主流分析框架为例， Spark 内核架构，计算模型和原理，了解分布式机器学习原理，能够处理和解决大规模数据分析预处理和模型训练。\n<ul>\n<li>了解和掌握 Spark 框架上的机器学习库 MLlib 的算法原理，核心数据抽象，以及应 用 MLlib。</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>电影推荐案例</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>学无止境，学海无涯</p>\n<p>专注深入的学习技术</p>\n</blockquote>\n<h3 id=\"机器学习基础\"><a class=\"markdownIt-Anchor\" href=\"#机器学习基础\"></a> 机器学习基础</h3>\n<h4 id=\"机器学习概念-应用与前沿\"><a class=\"markdownIt-Anchor\" href=\"#机器学习概念-应用与前沿\"></a> 机器学习概念、应用与前沿</h4>\n<ul>\n<li>内容<br>\n机器学习技术和应用场景的介绍。常见算法，主流的应用构建方法。主流机器学习框架介绍，针对机器学习场景能够更好的应用相关工具进行分析与处理。</li>\n<li>项目\n<ul>\n<li>鸢尾花分类实战</li>\n<li>分类预测实战</li>\n<li>回归预测实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数学基础-数学概念\"><a class=\"markdownIt-Anchor\" href=\"#数学基础-数学概念\"></a> 数学基础-数学概念</h4>\n<ul>\n<li>内容<br>\n机器学习中用到的数学基础由浅入深进行详细的梳理与讲解。主要涉及矩阵、导数、概率相关内容。<br>\n概率论，矩阵和凸优化的介绍，相应算法设计和原理；凸优化理论，流优化手段SGD等优化方法。</li>\n<li>项目\n<ul>\n<li>手写识别实战</li>\n<li>文本降维实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"特征工程-可视化\"><a class=\"markdownIt-Anchor\" href=\"#特征工程-可视化\"></a> 特征工程 &amp; 可视化</h4>\n<ul>\n<li>内容<br>\nPython数据预处理库，原始数据特征构建。特征选择，构建新特征，缺失值填充等特征工程方法学习。</li>\n<li>项目\n<ul>\n<li>Scikit-learn特征工程，网格搜索，超参数调优。</li>\n<li>泰坦尼克求生预测</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"机器学习算法学习\"><a class=\"markdownIt-Anchor\" href=\"#机器学习算法学习\"></a> 机器学习算法学习</h3>\n<h4 id=\"决策树与随机森林算法\"><a class=\"markdownIt-Anchor\" href=\"#决策树与随机森林算法\"></a> 决策树与随机森林算法</h4>\n<ul>\n<li>内容<br>\n决策树算法的原理，度量指标和算法变种。掌握和了解GBDT，AdaBoost，随机森林等集成学习模型的原理和集成学习算法。</li>\n<li>项目\n<ul>\n<li>鸢尾花分类实战</li>\n<li>金融反欺诈预测</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"分类算法\"><a class=\"markdownIt-Anchor\" href=\"#分类算法\"></a> 分类算法</h4>\n<ul>\n<li>内容\n<ul>\n<li>了解和掌握KNN、SVM及朴素贝叶斯算法原理。</li>\n<li>熟悉集成学习对于分类算法的优化过程。掌握数据降维方法应用。</li>\n<li>熟悉分类算法调参关键参数</li>\n<li>掌握不同分类算法的过拟合、欠拟合情景与调优</li>\n<li>掌握集成学习调优</li>\n<li>了解不同算法的共性与个性</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>手写图形数据降维与分类</li>\n<li>文本向量化实战</li>\n<li>文本分类实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"回归算法\"><a class=\"markdownIt-Anchor\" href=\"#回归算法\"></a> 回归算法</h4>\n<ul>\n<li>内容\n<ul>\n<li>主流回归模型，线性回归，逻辑回归LR、Softmax及其变种和扩展算法。</li>\n<li>梯度下降，牛顿法等优化方法，逻辑回归最优化问题的求解，正则化方法。</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>波士顿房价预测</li>\n<li>股票预测回归实战</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"大数据框架应用\"><a class=\"markdownIt-Anchor\" href=\"#大数据框架应用\"></a> 大数据框架应用</h3>\n<h4 id=\"聚类算法\"><a class=\"markdownIt-Anchor\" href=\"#聚类算法\"></a> 聚类算法</h4>\n<ul>\n<li>内容<br>\n无监督学习模型，了解主流的聚类算法。了解不同相似度计算算法。深入了解不同的数据降维方法。掌握文本降维方法(LDA)。\n<ul>\n<li>掌握 Kmeans 以及其衍生算法</li>\n<li>掌握 modelbased 聚类方法</li>\n<li>掌握无监督降维方法：PCA、ICA、字典学习</li>\n<li>掌握监督降维方法：LDA</li>\n<li>掌握文本降维方法：LDA</li>\n<li>深入理解聚类算法与分类算法的区别</li>\n<li>理解聚类算法的优缺点</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>新闻分类实战</li>\n<li>文本降维实战</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"深度学习框架-tensorflow\"><a class=\"markdownIt-Anchor\" href=\"#深度学习框架-tensorflow\"></a> 深度学习框架 TensorFlow</h4>\n<ul>\n<li>内容<br>\n通过掌握 Tensorflow 基本概念，计算模型 和原理，能够通过 Tensorflow 进行深度学习和模型构建与训练。学习掌握训练过程优化方法与问题优化。\n<ul>\n<li>学习变量作用域与变量命名</li>\n<li>搭建多层神经网络并完成优化</li>\n<li>正则化优化神经网络</li>\n<li>梯度问题与解决方法</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>图片分类实战</li>\n<li>贷款欺诈预测</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"大数据\"><a class=\"markdownIt-Anchor\" href=\"#大数据\"></a> 大数据</h4>\n<ul>\n<li>内容<br>\n大数据主流分析框架为例， Spark 内核架构，计算模型和原理，了解分布式机器学习原理，能够处理和解决大规模数据分析预处理和模型训练。\n<ul>\n<li>了解和掌握 Spark 框架上的机器学习库 MLlib 的算法原理，核心数据抽象，以及应 用 MLlib。</li>\n</ul>\n</li>\n<li>项目\n<ul>\n<li>电影推荐案例</li>\n</ul>\n</li>\n</ul>\n"},{"title":"JavaScript—2018 知识框架","catalog":true,"toc_nav_num":true,"date":"2018-05-12T02:51:24.000Z","subtitle":"Keep with new","header-img":"/img/article_header/article_header.png","catagories":["JavaScript"],"_content":"> 写在前面的话： 宝妈一枚，发现自己的记忆力不好（一孕傻三年），希望通过总结JavaScript的知识，强化记忆。最近趁着项目不忙，系统的学习了一下，让自己有个全面的知识体系，以及跟进JavaScript的发展步伐。(内容是中英文混杂，有时间后续会重写，有错误不全的地方请指正)\n\n\n### 一、基础JavaScript\n* Variable and Datatypes & variable mutation and type coercion\n* Operators\n* if/ else statements\n* Boolean logic and Switch statements\n* Functions\n* Statements and Expressions\n* Arrays\n* Objects and Properties\n* Object and Methods\n* Loop and Iteration\n* ES5, ES6/ ES2015 and ES2016\n***\n### 二、JavaScript运行原理\n* how code executed: JavaScript Parsers and Engines\n* Execution Contexts and Execution Stack\n* Execution Contexts in Detail: Creation and Execution Phases and Hoisting, hositing in practice\n* Scoping and the Scope Chain\n* 'this' keyword and 'this' in practice\n\n***\n### 三、浏览器中的JavaScript: DOM操作和事件\n* The DOM and DOM Manipulation\n* Math.random, Math.floor\n  * document.querySelector().textContent =\n  * document.querySelector().innerHTML =\n  * document.querySelector().style.display =\n  * document.querySelector().addEventListener(eventName,  function () {})\n  * document.querySelector().src\n  * document.getElementById()\n  * document.querySelector().classList.remove(className)\n  * document.querySelector().classList.add(className)\n  * document.querySelector().classList.toggle(className), if has class, delete, if not , add class\n* HTML and CSS crash course\n* Event and Event Handling: Rolling the Dice\n  * 事件只能在执行栈为空的时候来处理\n***\n### 四、高级JavaScript：Object和Function\n* Everything is an Object: Inheritance and the Prototype Chain\n  * primitives(number, string, boolean, undefined, null) and Objects\n  * constructors and instances\n  * inheritance\n  * prototypes and prototype chains\n  * every JavaScript object has a prototype property, which makes inheritance possible in JavaScript\n  * The prototype property of an object is where we put methods and properties that we want other objects to inherit\n  * The constructor's prototype property is NOT the prototype of the Cosntructor itself, it's the prototype of ALL instances that are created through it\n  * When a certain method (or property) is called, the search starts in the Object itself, and if it cannot be found, the search moves on to the objects's prototype. This continues until the mehtod is found: prototype chain.\n* Creating Objects: Function Constructors\n* The prototype Chain in the console\n  * \\__proto__  and prototype\n  * objectName.hasOwnProperty(propertyName)\n  * objectName instanceof Constructor\n  * console.info(objectName)\n * Creating Objects: Object.create\n  * Object.create(objectPrototype)\n  * Object.create(objectPrototype, obj), obj = { arr1: {value: 'attr'}, attr2: { vlaue: 'attr2'} }\n* Primitives vs Objects\n * primitives contain the values\n * objects point to the values\n* First Class Function: Passing Functions as Arguments\n * A function is an instance of the Object type\n * A function behaves like any other object\n * We can store function in a variable\n * We can pass a function as an argument to another function\n * We can return a function from a function\n * Above all we see in js, first-class functions\n* First Class Function: Functions Returning Functions\n* Immediately Invkoed Function Expression(IIFE)\n * 隔离作用域\n * 写惰性载入（惰性函数) : 例如浏览器的环境监测只需要执行一次，可以用这个\n* Closures\n * An inner function has always access to the variables and parameters of its outer function, even after the outer function has returned\n* Bind, Call and Apply\n * call(thisObj, otherArguments1, arguments2)\n* apply(thisObj, otherArgumentsArray)\n* bind(thisObj， arguments1), 不是立即调用，而是返回函数，参数可以分开设置，调用的时候在设第二个，函数curring\n***\n### 五、下一代JavaScript：ES6/ES2015\n* Variable Declarations with let and const\n * var , function scope\n * let, const , block scope, temporal dead zone\n   * accessing a let or constbefore it is declared throws ReferenceError\n* Blocks and IIFEs\n* String in ES6/ ES2015\n  * template literals (backtick (``) )\n  * string method\n    * str.startsWith('test')\n    * str.endsWith('test')\n    * str.includes('test')\n    * str.repeat(5)\n* Arrow Functions: Basics, Lexical 'this' keyword\n  * method call 'this' point to the object, function call 'this' point to the global object 'window'\n  * arrow function. sharing 'this' keywords with its surrounding\n* Destructuring\n  * [firstName, age] = ['claire', 20]\n  * {firstName, age } = { firstName: 'claire', age: 20}\n  * {firstName: a, age: b} = { firstName: 'claire', age: 20}\n* Arrays in ES6/ ES2015\n  * Array.from()\n  * el.className\n  * for ( el of arr)可以使用continue 和break\n  * forEach，map， continue，break不生效\n  * arr.findIndex(cur => cur > 18)\n  * arr.find(cur => cur > 18)\n* The spread operator\n  * ...[1, 3, 4]\n* Rest parameters\n* Default parameters\n* Maps\n  * new Map()\n  * map.set(key, value)\n  * map.get(key)\n  * map.size\n  * map.delete(key)\n  * map.has(key)\n  * map.clear()\n  * map.forEach\n  * for( let key of map)\n  * map.entries()\n* Classes\n  * static method in class\n  * class is no hosited, must first declared, then use\n  * only add method to class, not properties\n* Classes with Subclasses\n  * inheritance\n\n***\n### 六、异步JavaScript：Promise, Async/Await和Ajax\n* UnderStanding Asynchronous JavaScript: The Event Loop\n  * Event Loop\n* The Old Way: Asynchronous JavaScript with Callbacks\n* From Callback hell to Promises\n * Promise\n   * Object that keeps track about whether a certain event has happened already or not\n   * Determines what happens after the event has happened.\n   * Implements the concept of a furture value that we're expecting\n   * Promise state: pending-> settled/resolved--> fulfilled(rejected)\n* From Promises to Async/Await\n  * Async/Await is used to consume Promise\n  * Async function 总是返回Promise\n  * Promise vs Generator Function vs Async Await\n* Ajax and APIs\n  * Ajax: Asynchronous javascript and xml\n    * api: application programming interface own API, for data coming from you own server\n    * 3rd-party APIs:\n      * Google Maps\n      * Embed Youtube videos\n      * Weather data\n      * Movies data\n      * Send email or SMS\n.....\n   * 好用的跨域工具：https://crossorigin.me/: for cors when practice\n* Making Ajax Calls with Fetch and Promises, and Fetch and Async/Await\n   * fetch vs 传统Ajax(XMLHttpRequest)\n     * Fetch 优点主要有：\n       * 语法简洁，更加语义化\n       * 基于标准 Promise 实现，支持 async/await\n       * 同构方便，使用 isomorphic-fetch\n     * Fetch 常见坑\n       * Fetch 请求默认是不带 cookie 的，需要设置 fetch(url, {credentials: 'include'})\n     * 服务器返回 400，500 错误码时并不会  reject，只有网络错误这些导致请求不能完成时，fetch 才会被 reject。\n***\n### 七、现代JavaScript: 使用ES6, NPM, Babel and Webpack\n* A modern Setup: configuring webpack\n* A modern Setup: the webpack Dev Server\n* A modern Setup: Babel\n* Planning Project with MVC\n* How ES6 Modules work\n* Implementing Persistent Data with localStorage\n","source":"_posts/JavaScript-2018-Frame.md","raw":"---\ntitle: \"JavaScript—2018 知识框架\"\ncatalog: true\ntoc_nav_num: true\ndate: 2018-05-12 10:51:24\nsubtitle: \"Keep with new\"\nheader-img: \"/img/article_header/article_header.png\"\ntags:\n- JavaScript\ncatagories:\n- JavaScript\n\n---\n> 写在前面的话： 宝妈一枚，发现自己的记忆力不好（一孕傻三年），希望通过总结JavaScript的知识，强化记忆。最近趁着项目不忙，系统的学习了一下，让自己有个全面的知识体系，以及跟进JavaScript的发展步伐。(内容是中英文混杂，有时间后续会重写，有错误不全的地方请指正)\n\n\n### 一、基础JavaScript\n* Variable and Datatypes & variable mutation and type coercion\n* Operators\n* if/ else statements\n* Boolean logic and Switch statements\n* Functions\n* Statements and Expressions\n* Arrays\n* Objects and Properties\n* Object and Methods\n* Loop and Iteration\n* ES5, ES6/ ES2015 and ES2016\n***\n### 二、JavaScript运行原理\n* how code executed: JavaScript Parsers and Engines\n* Execution Contexts and Execution Stack\n* Execution Contexts in Detail: Creation and Execution Phases and Hoisting, hositing in practice\n* Scoping and the Scope Chain\n* 'this' keyword and 'this' in practice\n\n***\n### 三、浏览器中的JavaScript: DOM操作和事件\n* The DOM and DOM Manipulation\n* Math.random, Math.floor\n  * document.querySelector().textContent =\n  * document.querySelector().innerHTML =\n  * document.querySelector().style.display =\n  * document.querySelector().addEventListener(eventName,  function () {})\n  * document.querySelector().src\n  * document.getElementById()\n  * document.querySelector().classList.remove(className)\n  * document.querySelector().classList.add(className)\n  * document.querySelector().classList.toggle(className), if has class, delete, if not , add class\n* HTML and CSS crash course\n* Event and Event Handling: Rolling the Dice\n  * 事件只能在执行栈为空的时候来处理\n***\n### 四、高级JavaScript：Object和Function\n* Everything is an Object: Inheritance and the Prototype Chain\n  * primitives(number, string, boolean, undefined, null) and Objects\n  * constructors and instances\n  * inheritance\n  * prototypes and prototype chains\n  * every JavaScript object has a prototype property, which makes inheritance possible in JavaScript\n  * The prototype property of an object is where we put methods and properties that we want other objects to inherit\n  * The constructor's prototype property is NOT the prototype of the Cosntructor itself, it's the prototype of ALL instances that are created through it\n  * When a certain method (or property) is called, the search starts in the Object itself, and if it cannot be found, the search moves on to the objects's prototype. This continues until the mehtod is found: prototype chain.\n* Creating Objects: Function Constructors\n* The prototype Chain in the console\n  * \\__proto__  and prototype\n  * objectName.hasOwnProperty(propertyName)\n  * objectName instanceof Constructor\n  * console.info(objectName)\n * Creating Objects: Object.create\n  * Object.create(objectPrototype)\n  * Object.create(objectPrototype, obj), obj = { arr1: {value: 'attr'}, attr2: { vlaue: 'attr2'} }\n* Primitives vs Objects\n * primitives contain the values\n * objects point to the values\n* First Class Function: Passing Functions as Arguments\n * A function is an instance of the Object type\n * A function behaves like any other object\n * We can store function in a variable\n * We can pass a function as an argument to another function\n * We can return a function from a function\n * Above all we see in js, first-class functions\n* First Class Function: Functions Returning Functions\n* Immediately Invkoed Function Expression(IIFE)\n * 隔离作用域\n * 写惰性载入（惰性函数) : 例如浏览器的环境监测只需要执行一次，可以用这个\n* Closures\n * An inner function has always access to the variables and parameters of its outer function, even after the outer function has returned\n* Bind, Call and Apply\n * call(thisObj, otherArguments1, arguments2)\n* apply(thisObj, otherArgumentsArray)\n* bind(thisObj， arguments1), 不是立即调用，而是返回函数，参数可以分开设置，调用的时候在设第二个，函数curring\n***\n### 五、下一代JavaScript：ES6/ES2015\n* Variable Declarations with let and const\n * var , function scope\n * let, const , block scope, temporal dead zone\n   * accessing a let or constbefore it is declared throws ReferenceError\n* Blocks and IIFEs\n* String in ES6/ ES2015\n  * template literals (backtick (``) )\n  * string method\n    * str.startsWith('test')\n    * str.endsWith('test')\n    * str.includes('test')\n    * str.repeat(5)\n* Arrow Functions: Basics, Lexical 'this' keyword\n  * method call 'this' point to the object, function call 'this' point to the global object 'window'\n  * arrow function. sharing 'this' keywords with its surrounding\n* Destructuring\n  * [firstName, age] = ['claire', 20]\n  * {firstName, age } = { firstName: 'claire', age: 20}\n  * {firstName: a, age: b} = { firstName: 'claire', age: 20}\n* Arrays in ES6/ ES2015\n  * Array.from()\n  * el.className\n  * for ( el of arr)可以使用continue 和break\n  * forEach，map， continue，break不生效\n  * arr.findIndex(cur => cur > 18)\n  * arr.find(cur => cur > 18)\n* The spread operator\n  * ...[1, 3, 4]\n* Rest parameters\n* Default parameters\n* Maps\n  * new Map()\n  * map.set(key, value)\n  * map.get(key)\n  * map.size\n  * map.delete(key)\n  * map.has(key)\n  * map.clear()\n  * map.forEach\n  * for( let key of map)\n  * map.entries()\n* Classes\n  * static method in class\n  * class is no hosited, must first declared, then use\n  * only add method to class, not properties\n* Classes with Subclasses\n  * inheritance\n\n***\n### 六、异步JavaScript：Promise, Async/Await和Ajax\n* UnderStanding Asynchronous JavaScript: The Event Loop\n  * Event Loop\n* The Old Way: Asynchronous JavaScript with Callbacks\n* From Callback hell to Promises\n * Promise\n   * Object that keeps track about whether a certain event has happened already or not\n   * Determines what happens after the event has happened.\n   * Implements the concept of a furture value that we're expecting\n   * Promise state: pending-> settled/resolved--> fulfilled(rejected)\n* From Promises to Async/Await\n  * Async/Await is used to consume Promise\n  * Async function 总是返回Promise\n  * Promise vs Generator Function vs Async Await\n* Ajax and APIs\n  * Ajax: Asynchronous javascript and xml\n    * api: application programming interface own API, for data coming from you own server\n    * 3rd-party APIs:\n      * Google Maps\n      * Embed Youtube videos\n      * Weather data\n      * Movies data\n      * Send email or SMS\n.....\n   * 好用的跨域工具：https://crossorigin.me/: for cors when practice\n* Making Ajax Calls with Fetch and Promises, and Fetch and Async/Await\n   * fetch vs 传统Ajax(XMLHttpRequest)\n     * Fetch 优点主要有：\n       * 语法简洁，更加语义化\n       * 基于标准 Promise 实现，支持 async/await\n       * 同构方便，使用 isomorphic-fetch\n     * Fetch 常见坑\n       * Fetch 请求默认是不带 cookie 的，需要设置 fetch(url, {credentials: 'include'})\n     * 服务器返回 400，500 错误码时并不会  reject，只有网络错误这些导致请求不能完成时，fetch 才会被 reject。\n***\n### 七、现代JavaScript: 使用ES6, NPM, Babel and Webpack\n* A modern Setup: configuring webpack\n* A modern Setup: the webpack Dev Server\n* A modern Setup: Babel\n* Planning Project with MVC\n* How ES6 Modules work\n* Implementing Persistent Data with localStorage\n","slug":"JavaScript-2018-Frame","published":1,"updated":"2019-04-03T06:46:35.614Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjysio1qb0008chov64xqowgl","content":"<blockquote>\n<p>写在前面的话： 宝妈一枚，发现自己的记忆力不好（一孕傻三年），希望通过总结JavaScript的知识，强化记忆。最近趁着项目不忙，系统的学习了一下，让自己有个全面的知识体系，以及跟进JavaScript的发展步伐。(内容是中英文混杂，有时间后续会重写，有错误不全的地方请指正)</p>\n</blockquote>\n<h3 id=\"一-基础javascript\"><a class=\"markdownIt-Anchor\" href=\"#一-基础javascript\"></a> 一、基础JavaScript</h3>\n<ul>\n<li>Variable and Datatypes &amp; variable mutation and type coercion</li>\n<li>Operators</li>\n<li>if/ else statements</li>\n<li>Boolean logic and Switch statements</li>\n<li>Functions</li>\n<li>Statements and Expressions</li>\n<li>Arrays</li>\n<li>Objects and Properties</li>\n<li>Object and Methods</li>\n<li>Loop and Iteration</li>\n<li>ES5, ES6/ ES2015 and ES2016</li>\n</ul>\n<hr>\n<h3 id=\"二-javascript运行原理\"><a class=\"markdownIt-Anchor\" href=\"#二-javascript运行原理\"></a> 二、JavaScript运行原理</h3>\n<ul>\n<li>how code executed: JavaScript Parsers and Engines</li>\n<li>Execution Contexts and Execution Stack</li>\n<li>Execution Contexts in Detail: Creation and Execution Phases and Hoisting, hositing in practice</li>\n<li>Scoping and the Scope Chain</li>\n<li>‘this’ keyword and ‘this’ in practice</li>\n</ul>\n<hr>\n<h3 id=\"三-浏览器中的javascript-dom操作和事件\"><a class=\"markdownIt-Anchor\" href=\"#三-浏览器中的javascript-dom操作和事件\"></a> 三、浏览器中的JavaScript: DOM操作和事件</h3>\n<ul>\n<li>The DOM and DOM Manipulation</li>\n<li>Math.random, Math.floor\n<ul>\n<li>document.querySelector().textContent =</li>\n<li>document.querySelector().innerHTML =</li>\n<li>document.querySelector().style.display =</li>\n<li>document.querySelector().addEventListener(eventName,  function () {})</li>\n<li>document.querySelector().src</li>\n<li>document.getElementById()</li>\n<li>document.querySelector().classList.remove(className)</li>\n<li>document.querySelector().classList.add(className)</li>\n<li>document.querySelector().classList.toggle(className), if has class, delete, if not , add class</li>\n</ul>\n</li>\n<li>HTML and CSS crash course</li>\n<li>Event and Event Handling: Rolling the Dice\n<ul>\n<li>事件只能在执行栈为空的时候来处理</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"四-高级javascriptobject和function\"><a class=\"markdownIt-Anchor\" href=\"#四-高级javascriptobject和function\"></a> 四、高级JavaScript：Object和Function</h3>\n<ul>\n<li>Everything is an Object: Inheritance and the Prototype Chain\n<ul>\n<li>primitives(number, string, boolean, undefined, null) and Objects</li>\n<li>constructors and instances</li>\n<li>inheritance</li>\n<li>prototypes and prototype chains</li>\n<li>every JavaScript object has a prototype property, which makes inheritance possible in JavaScript</li>\n<li>The prototype property of an object is where we put methods and properties that we want other objects to inherit</li>\n<li>The constructor’s prototype property is NOT the prototype of the Cosntructor itself, it’s the prototype of ALL instances that are created through it</li>\n<li>When a certain method (or property) is called, the search starts in the Object itself, and if it cannot be found, the search moves on to the objects’s prototype. This continues until the mehtod is found: prototype chain.</li>\n</ul>\n</li>\n<li>Creating Objects: Function Constructors</li>\n<li>The prototype Chain in the console\n<ul>\n<li>_<em>proto</em>_  and prototype</li>\n<li>objectName.hasOwnProperty(propertyName)</li>\n<li>objectName instanceof Constructor</li>\n<li><a href=\"http://console.info\" target=\"_blank\" rel=\"noopener\">console.info</a>(objectName)</li>\n</ul>\n</li>\n<li>Creating Objects: Object.create</li>\n<li>Object.create(objectPrototype)</li>\n<li>Object.create(objectPrototype, obj), obj = { arr1: {value: ‘attr’}, attr2: { vlaue: ‘attr2’} }</li>\n<li>Primitives vs Objects</li>\n<li>primitives contain the values</li>\n<li>objects point to the values</li>\n<li>First Class Function: Passing Functions as Arguments</li>\n<li>A function is an instance of the Object type</li>\n<li>A function behaves like any other object</li>\n<li>We can store function in a variable</li>\n<li>We can pass a function as an argument to another function</li>\n<li>We can return a function from a function</li>\n<li>Above all we see in js, first-class functions</li>\n<li>First Class Function: Functions Returning Functions</li>\n<li>Immediately Invkoed Function Expression(IIFE)</li>\n<li>隔离作用域</li>\n<li>写惰性载入（惰性函数) : 例如浏览器的环境监测只需要执行一次，可以用这个</li>\n<li>Closures</li>\n<li>An inner function has always access to the variables and parameters of its outer function, even after the outer function has returned</li>\n<li>Bind, Call and Apply</li>\n<li>call(thisObj, otherArguments1, arguments2)</li>\n<li>apply(thisObj, otherArgumentsArray)</li>\n<li>bind(thisObj， arguments1), 不是立即调用，而是返回函数，参数可以分开设置，调用的时候在设第二个，函数curring</li>\n</ul>\n<hr>\n<h3 id=\"五-下一代javascriptes6es2015\"><a class=\"markdownIt-Anchor\" href=\"#五-下一代javascriptes6es2015\"></a> 五、下一代JavaScript：ES6/ES2015</h3>\n<ul>\n<li>Variable Declarations with let and const</li>\n<li>var , function scope</li>\n<li>let, const , block scope, temporal dead zone\n<ul>\n<li>accessing a let or constbefore it is declared throws ReferenceError</li>\n</ul>\n</li>\n<li>Blocks and IIFEs</li>\n<li>String in ES6/ ES2015\n<ul>\n<li>template literals (backtick (``) )</li>\n<li>string method\n<ul>\n<li>str.startsWith(‘test’)</li>\n<li>str.endsWith(‘test’)</li>\n<li>str.includes(‘test’)</li>\n<li>str.repeat(5)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Arrow Functions: Basics, Lexical ‘this’ keyword\n<ul>\n<li>method call ‘this’ point to the object, function call ‘this’ point to the global object ‘window’</li>\n<li>arrow function. sharing ‘this’ keywords with its surrounding</li>\n</ul>\n</li>\n<li>Destructuring\n<ul>\n<li>[firstName, age] = [‘claire’, 20]</li>\n<li>{firstName, age } = { firstName: ‘claire’, age: 20}</li>\n<li>{firstName: a, age: b} = { firstName: ‘claire’, age: 20}</li>\n</ul>\n</li>\n<li>Arrays in ES6/ ES2015\n<ul>\n<li>Array.from()</li>\n<li>el.className</li>\n<li>for ( el of arr)可以使用continue 和break</li>\n<li>forEach，map， continue，break不生效</li>\n<li>arr.findIndex(cur =&gt; cur &gt; 18)</li>\n<li>arr.find(cur =&gt; cur &gt; 18)</li>\n</ul>\n</li>\n<li>The spread operator\n<ul>\n<li>…[1, 3, 4]</li>\n</ul>\n</li>\n<li>Rest parameters</li>\n<li>Default parameters</li>\n<li>Maps\n<ul>\n<li>new Map()</li>\n<li>map.set(key, value)</li>\n<li>map.get(key)</li>\n<li>map.size</li>\n<li>map.delete(key)</li>\n<li>map.has(key)</li>\n<li>map.clear()</li>\n<li>map.forEach</li>\n<li>for( let key of map)</li>\n<li>map.entries()</li>\n</ul>\n</li>\n<li>Classes\n<ul>\n<li>static method in class</li>\n<li>class is no hosited, must first declared, then use</li>\n<li>only add method to class, not properties</li>\n</ul>\n</li>\n<li>Classes with Subclasses\n<ul>\n<li>inheritance</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"六-异步javascriptpromise-asyncawait和ajax\"><a class=\"markdownIt-Anchor\" href=\"#六-异步javascriptpromise-asyncawait和ajax\"></a> 六、异步JavaScript：Promise, Async/Await和Ajax</h3>\n<ul>\n<li>UnderStanding Asynchronous JavaScript: The Event Loop\n<ul>\n<li>Event Loop</li>\n</ul>\n</li>\n<li>The Old Way: Asynchronous JavaScript with Callbacks</li>\n<li>From Callback hell to Promises</li>\n<li>Promise\n<ul>\n<li>Object that keeps track about whether a certain event has happened already or not</li>\n<li>Determines what happens after the event has happened.</li>\n<li>Implements the concept of a furture value that we’re expecting</li>\n<li>Promise state: pending-&gt; settled/resolved–&gt; fulfilled(rejected)</li>\n</ul>\n</li>\n<li>From Promises to Async/Await\n<ul>\n<li>Async/Await is used to consume Promise</li>\n<li>Async function 总是返回Promise</li>\n<li>Promise vs Generator Function vs Async Await</li>\n</ul>\n</li>\n<li>Ajax and APIs\n<ul>\n<li>Ajax: Asynchronous javascript and xml\n<ul>\n<li>api: application programming interface own API, for data coming from you own server</li>\n<li>3rd-party APIs:\n<ul>\n<li>Google Maps</li>\n<li>Embed Youtube videos</li>\n<li>Weather data</li>\n<li>Movies data</li>\n<li>Send email or SMS<br>\n…</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>好用的跨域工具：<a href=\"https://crossorigin.me/:\" target=\"_blank\" rel=\"noopener\">https://crossorigin.me/:</a> for cors when practice</li>\n</ul>\n</li>\n<li>Making Ajax Calls with Fetch and Promises, and Fetch and Async/Await\n<ul>\n<li>fetch vs 传统Ajax(XMLHttpRequest)\n<ul>\n<li>Fetch 优点主要有：\n<ul>\n<li>语法简洁，更加语义化</li>\n<li>基于标准 Promise 实现，支持 async/await</li>\n<li>同构方便，使用 isomorphic-fetch</li>\n</ul>\n</li>\n<li>Fetch 常见坑\n<ul>\n<li>Fetch 请求默认是不带 cookie 的，需要设置 fetch(url, {credentials: ‘include’})</li>\n</ul>\n</li>\n<li>服务器返回 400，500 错误码时并不会  reject，只有网络错误这些导致请求不能完成时，fetch 才会被 reject。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"七-现代javascript-使用es6-npm-babel-and-webpack\"><a class=\"markdownIt-Anchor\" href=\"#七-现代javascript-使用es6-npm-babel-and-webpack\"></a> 七、现代JavaScript: 使用ES6, NPM, Babel and Webpack</h3>\n<ul>\n<li>A modern Setup: configuring webpack</li>\n<li>A modern Setup: the webpack Dev Server</li>\n<li>A modern Setup: Babel</li>\n<li>Planning Project with MVC</li>\n<li>How ES6 Modules work</li>\n<li>Implementing Persistent Data with localStorage</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>写在前面的话： 宝妈一枚，发现自己的记忆力不好（一孕傻三年），希望通过总结JavaScript的知识，强化记忆。最近趁着项目不忙，系统的学习了一下，让自己有个全面的知识体系，以及跟进JavaScript的发展步伐。(内容是中英文混杂，有时间后续会重写，有错误不全的地方请指正)</p>\n</blockquote>\n<h3 id=\"一-基础javascript\"><a class=\"markdownIt-Anchor\" href=\"#一-基础javascript\"></a> 一、基础JavaScript</h3>\n<ul>\n<li>Variable and Datatypes &amp; variable mutation and type coercion</li>\n<li>Operators</li>\n<li>if/ else statements</li>\n<li>Boolean logic and Switch statements</li>\n<li>Functions</li>\n<li>Statements and Expressions</li>\n<li>Arrays</li>\n<li>Objects and Properties</li>\n<li>Object and Methods</li>\n<li>Loop and Iteration</li>\n<li>ES5, ES6/ ES2015 and ES2016</li>\n</ul>\n<hr>\n<h3 id=\"二-javascript运行原理\"><a class=\"markdownIt-Anchor\" href=\"#二-javascript运行原理\"></a> 二、JavaScript运行原理</h3>\n<ul>\n<li>how code executed: JavaScript Parsers and Engines</li>\n<li>Execution Contexts and Execution Stack</li>\n<li>Execution Contexts in Detail: Creation and Execution Phases and Hoisting, hositing in practice</li>\n<li>Scoping and the Scope Chain</li>\n<li>‘this’ keyword and ‘this’ in practice</li>\n</ul>\n<hr>\n<h3 id=\"三-浏览器中的javascript-dom操作和事件\"><a class=\"markdownIt-Anchor\" href=\"#三-浏览器中的javascript-dom操作和事件\"></a> 三、浏览器中的JavaScript: DOM操作和事件</h3>\n<ul>\n<li>The DOM and DOM Manipulation</li>\n<li>Math.random, Math.floor\n<ul>\n<li>document.querySelector().textContent =</li>\n<li>document.querySelector().innerHTML =</li>\n<li>document.querySelector().style.display =</li>\n<li>document.querySelector().addEventListener(eventName,  function () {})</li>\n<li>document.querySelector().src</li>\n<li>document.getElementById()</li>\n<li>document.querySelector().classList.remove(className)</li>\n<li>document.querySelector().classList.add(className)</li>\n<li>document.querySelector().classList.toggle(className), if has class, delete, if not , add class</li>\n</ul>\n</li>\n<li>HTML and CSS crash course</li>\n<li>Event and Event Handling: Rolling the Dice\n<ul>\n<li>事件只能在执行栈为空的时候来处理</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"四-高级javascriptobject和function\"><a class=\"markdownIt-Anchor\" href=\"#四-高级javascriptobject和function\"></a> 四、高级JavaScript：Object和Function</h3>\n<ul>\n<li>Everything is an Object: Inheritance and the Prototype Chain\n<ul>\n<li>primitives(number, string, boolean, undefined, null) and Objects</li>\n<li>constructors and instances</li>\n<li>inheritance</li>\n<li>prototypes and prototype chains</li>\n<li>every JavaScript object has a prototype property, which makes inheritance possible in JavaScript</li>\n<li>The prototype property of an object is where we put methods and properties that we want other objects to inherit</li>\n<li>The constructor’s prototype property is NOT the prototype of the Cosntructor itself, it’s the prototype of ALL instances that are created through it</li>\n<li>When a certain method (or property) is called, the search starts in the Object itself, and if it cannot be found, the search moves on to the objects’s prototype. This continues until the mehtod is found: prototype chain.</li>\n</ul>\n</li>\n<li>Creating Objects: Function Constructors</li>\n<li>The prototype Chain in the console\n<ul>\n<li>_<em>proto</em>_  and prototype</li>\n<li>objectName.hasOwnProperty(propertyName)</li>\n<li>objectName instanceof Constructor</li>\n<li><a href=\"http://console.info\" target=\"_blank\" rel=\"noopener\">console.info</a>(objectName)</li>\n</ul>\n</li>\n<li>Creating Objects: Object.create</li>\n<li>Object.create(objectPrototype)</li>\n<li>Object.create(objectPrototype, obj), obj = { arr1: {value: ‘attr’}, attr2: { vlaue: ‘attr2’} }</li>\n<li>Primitives vs Objects</li>\n<li>primitives contain the values</li>\n<li>objects point to the values</li>\n<li>First Class Function: Passing Functions as Arguments</li>\n<li>A function is an instance of the Object type</li>\n<li>A function behaves like any other object</li>\n<li>We can store function in a variable</li>\n<li>We can pass a function as an argument to another function</li>\n<li>We can return a function from a function</li>\n<li>Above all we see in js, first-class functions</li>\n<li>First Class Function: Functions Returning Functions</li>\n<li>Immediately Invkoed Function Expression(IIFE)</li>\n<li>隔离作用域</li>\n<li>写惰性载入（惰性函数) : 例如浏览器的环境监测只需要执行一次，可以用这个</li>\n<li>Closures</li>\n<li>An inner function has always access to the variables and parameters of its outer function, even after the outer function has returned</li>\n<li>Bind, Call and Apply</li>\n<li>call(thisObj, otherArguments1, arguments2)</li>\n<li>apply(thisObj, otherArgumentsArray)</li>\n<li>bind(thisObj， arguments1), 不是立即调用，而是返回函数，参数可以分开设置，调用的时候在设第二个，函数curring</li>\n</ul>\n<hr>\n<h3 id=\"五-下一代javascriptes6es2015\"><a class=\"markdownIt-Anchor\" href=\"#五-下一代javascriptes6es2015\"></a> 五、下一代JavaScript：ES6/ES2015</h3>\n<ul>\n<li>Variable Declarations with let and const</li>\n<li>var , function scope</li>\n<li>let, const , block scope, temporal dead zone\n<ul>\n<li>accessing a let or constbefore it is declared throws ReferenceError</li>\n</ul>\n</li>\n<li>Blocks and IIFEs</li>\n<li>String in ES6/ ES2015\n<ul>\n<li>template literals (backtick (``) )</li>\n<li>string method\n<ul>\n<li>str.startsWith(‘test’)</li>\n<li>str.endsWith(‘test’)</li>\n<li>str.includes(‘test’)</li>\n<li>str.repeat(5)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Arrow Functions: Basics, Lexical ‘this’ keyword\n<ul>\n<li>method call ‘this’ point to the object, function call ‘this’ point to the global object ‘window’</li>\n<li>arrow function. sharing ‘this’ keywords with its surrounding</li>\n</ul>\n</li>\n<li>Destructuring\n<ul>\n<li>[firstName, age] = [‘claire’, 20]</li>\n<li>{firstName, age } = { firstName: ‘claire’, age: 20}</li>\n<li>{firstName: a, age: b} = { firstName: ‘claire’, age: 20}</li>\n</ul>\n</li>\n<li>Arrays in ES6/ ES2015\n<ul>\n<li>Array.from()</li>\n<li>el.className</li>\n<li>for ( el of arr)可以使用continue 和break</li>\n<li>forEach，map， continue，break不生效</li>\n<li>arr.findIndex(cur =&gt; cur &gt; 18)</li>\n<li>arr.find(cur =&gt; cur &gt; 18)</li>\n</ul>\n</li>\n<li>The spread operator\n<ul>\n<li>…[1, 3, 4]</li>\n</ul>\n</li>\n<li>Rest parameters</li>\n<li>Default parameters</li>\n<li>Maps\n<ul>\n<li>new Map()</li>\n<li>map.set(key, value)</li>\n<li>map.get(key)</li>\n<li>map.size</li>\n<li>map.delete(key)</li>\n<li>map.has(key)</li>\n<li>map.clear()</li>\n<li>map.forEach</li>\n<li>for( let key of map)</li>\n<li>map.entries()</li>\n</ul>\n</li>\n<li>Classes\n<ul>\n<li>static method in class</li>\n<li>class is no hosited, must first declared, then use</li>\n<li>only add method to class, not properties</li>\n</ul>\n</li>\n<li>Classes with Subclasses\n<ul>\n<li>inheritance</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"六-异步javascriptpromise-asyncawait和ajax\"><a class=\"markdownIt-Anchor\" href=\"#六-异步javascriptpromise-asyncawait和ajax\"></a> 六、异步JavaScript：Promise, Async/Await和Ajax</h3>\n<ul>\n<li>UnderStanding Asynchronous JavaScript: The Event Loop\n<ul>\n<li>Event Loop</li>\n</ul>\n</li>\n<li>The Old Way: Asynchronous JavaScript with Callbacks</li>\n<li>From Callback hell to Promises</li>\n<li>Promise\n<ul>\n<li>Object that keeps track about whether a certain event has happened already or not</li>\n<li>Determines what happens after the event has happened.</li>\n<li>Implements the concept of a furture value that we’re expecting</li>\n<li>Promise state: pending-&gt; settled/resolved–&gt; fulfilled(rejected)</li>\n</ul>\n</li>\n<li>From Promises to Async/Await\n<ul>\n<li>Async/Await is used to consume Promise</li>\n<li>Async function 总是返回Promise</li>\n<li>Promise vs Generator Function vs Async Await</li>\n</ul>\n</li>\n<li>Ajax and APIs\n<ul>\n<li>Ajax: Asynchronous javascript and xml\n<ul>\n<li>api: application programming interface own API, for data coming from you own server</li>\n<li>3rd-party APIs:\n<ul>\n<li>Google Maps</li>\n<li>Embed Youtube videos</li>\n<li>Weather data</li>\n<li>Movies data</li>\n<li>Send email or SMS<br>\n…</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>好用的跨域工具：<a href=\"https://crossorigin.me/:\" target=\"_blank\" rel=\"noopener\">https://crossorigin.me/:</a> for cors when practice</li>\n</ul>\n</li>\n<li>Making Ajax Calls with Fetch and Promises, and Fetch and Async/Await\n<ul>\n<li>fetch vs 传统Ajax(XMLHttpRequest)\n<ul>\n<li>Fetch 优点主要有：\n<ul>\n<li>语法简洁，更加语义化</li>\n<li>基于标准 Promise 实现，支持 async/await</li>\n<li>同构方便，使用 isomorphic-fetch</li>\n</ul>\n</li>\n<li>Fetch 常见坑\n<ul>\n<li>Fetch 请求默认是不带 cookie 的，需要设置 fetch(url, {credentials: ‘include’})</li>\n</ul>\n</li>\n<li>服务器返回 400，500 错误码时并不会  reject，只有网络错误这些导致请求不能完成时，fetch 才会被 reject。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"七-现代javascript-使用es6-npm-babel-and-webpack\"><a class=\"markdownIt-Anchor\" href=\"#七-现代javascript-使用es6-npm-babel-and-webpack\"></a> 七、现代JavaScript: 使用ES6, NPM, Babel and Webpack</h3>\n<ul>\n<li>A modern Setup: configuring webpack</li>\n<li>A modern Setup: the webpack Dev Server</li>\n<li>A modern Setup: Babel</li>\n<li>Planning Project with MVC</li>\n<li>How ES6 Modules work</li>\n<li>Implementing Persistent Data with localStorage</li>\n</ul>\n"},{"title":"工具以及框架总结","catalog":true,"toc_nav_num":true,"date":"2019-08-02T10:30:24.000Z","subtitle":null,"header-img":"/img/article_header/article_header.png","catagories":["工具以及框架总结"],"_content":"\n\n#### 数据科学\n* 语言\n  - python\n* 包\n  - numpy\n  - pandas\n  - sqlalchemy\n  - lxml\n  - html5lib\n  - BeautifulSoup4\n* 数据可视化\n  - Matplotlib\n  - Seaborn\n  - Pandas内嵌数据可视化\n  - Plotly\n  - Cufflinks\n  - Geographical Plotting","source":"_posts/框架以及工具总结.md","raw":"---\ntitle: \"工具以及框架总结\"\ncatalog: true\ntoc_nav_num: true\n# mathjax: true\ndate: 2019-08-02 18:30:24\nsubtitle:\nheader-img: \"/img/article_header/article_header.png\"\ntags:\n- 前端，数据科学\ncatagories:\n- 工具以及框架总结\n\n---\n\n\n#### 数据科学\n* 语言\n  - python\n* 包\n  - numpy\n  - pandas\n  - sqlalchemy\n  - lxml\n  - html5lib\n  - BeautifulSoup4\n* 数据可视化\n  - Matplotlib\n  - Seaborn\n  - Pandas内嵌数据可视化\n  - Plotly\n  - Cufflinks\n  - Geographical Plotting","slug":"框架以及工具总结","published":1,"updated":"2019-08-02T09:20:14.490Z","_id":"cjyts80iq0000loovclng513b","comments":1,"layout":"post","photos":[],"link":"","content":"<h4 id=\"数据科学\"><a class=\"markdownIt-Anchor\" href=\"#数据科学\"></a> 数据科学</h4>\n<ul>\n<li>语言\n<ul>\n<li>python</li>\n</ul>\n</li>\n<li>包\n<ul>\n<li>numpy</li>\n<li>pandas</li>\n<li>sqlalchemy</li>\n<li>lxml</li>\n<li>html5lib</li>\n<li>BeautifulSoup4</li>\n</ul>\n</li>\n<li>数据可视化\n<ul>\n<li>Matplotlib</li>\n<li>Seaborn</li>\n<li>Pandas内嵌数据可视化</li>\n<li>Plotly</li>\n<li>Cufflinks</li>\n<li>Geographical Plotting</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"数据科学\"><a class=\"markdownIt-Anchor\" href=\"#数据科学\"></a> 数据科学</h4>\n<ul>\n<li>语言\n<ul>\n<li>python</li>\n</ul>\n</li>\n<li>包\n<ul>\n<li>numpy</li>\n<li>pandas</li>\n<li>sqlalchemy</li>\n<li>lxml</li>\n<li>html5lib</li>\n<li>BeautifulSoup4</li>\n</ul>\n</li>\n<li>数据可视化\n<ul>\n<li>Matplotlib</li>\n<li>Seaborn</li>\n<li>Pandas内嵌数据可视化</li>\n<li>Plotly</li>\n<li>Cufflinks</li>\n<li>Geographical Plotting</li>\n</ul>\n</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjysio1q00001chov15vtufud","tag_id":"cjysio1q70005chov3dcs83v3","_id":"cjysio1qd000achovitnsh6sy"},{"post_id":"cjysio1q50003chovt0yn9pwv","tag_id":"cjysio1qd0009choviyaeruql","_id":"cjysio1qf000cchovkgqei4if"},{"post_id":"cjysio1q90006chovjq4euvgz","tag_id":"cjysio1qe000bchov09dc00bt","_id":"cjysio1qg000echovhvtw46v9"},{"post_id":"cjysio1qb0008chov64xqowgl","tag_id":"cjysio1qg000dchovh069ahgn","_id":"cjysio1qg000fchovcsapj9vv"},{"post_id":"cjyts80iq0000loovclng513b","tag_id":"cjyts80iv0001loovb6edkdu0","_id":"cjyts80j00002loovwjponbq4"}],"Tag":[{"name":"特征工程","_id":"cjysio1q70005chov3dcs83v3"},{"name":"优化方法","_id":"cjysio1qd0009choviyaeruql"},{"name":"学习计划","_id":"cjysio1qe000bchov09dc00bt"},{"name":"JavaScript","_id":"cjysio1qg000dchovh069ahgn"},{"name":"前端，数据科学","_id":"cjyts80iv0001loovb6edkdu0"}]}}